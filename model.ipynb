{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "EyRf9i2S9cEU",
    "outputId": "e7e3fdb5-29e4-4e1b-88d6-3a5b645761d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lumen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lumen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lumen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import random\n",
    "import operator\n",
    "import requests\n",
    "import nltk\n",
    "from numpy.random import seed\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "VqnkVhi89cEf",
    "outputId": "00b4b628-ec03-46fc-8dfa-b2cd76827bd5"
   },
   "outputs": [],
   "source": [
    "path1= 'restaurant_true.txt'\n",
    "path2= 'restaurant_false.txt'\n",
    "\n",
    "ds_res_true=open(path1).readlines()\n",
    "ds_res_false=open(path2).readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nJM6URcm9cEi"
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(ds_res_true)):\n",
    "  ds_res_true[i]=ds_res_true[i][:-1]\n",
    "for i in range(0,len(ds_res_false)):\n",
    "  ds_res_false[i]=ds_res_false[i][:-1]\n",
    "\n",
    "\n",
    "df_res=[]   \n",
    "\n",
    "for i in range(0,len(ds_res_true)):\n",
    "  df_res.append(list([ds_res_true[i],1]))\n",
    "for i in range(0,len(ds_res_false)):\n",
    "  df_res.append(list([ds_res_false[i],0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pEUCtv4N9cEr"
   },
   "outputs": [],
   "source": [
    "random.Random(102).shuffle(df_res)\n",
    "random.Random(32).shuffle(df_doc)\n",
    "\n",
    "def train_val_test_split(df):\n",
    "    df_train=[]\n",
    "    df_val=[]         \n",
    "    df_test=[]\n",
    "    for i in range(0,len(df)):\n",
    "      if i < int(len(df)*0.8):\n",
    "        df_train.append(df[i])\n",
    "      elif (i > int(len(df)*0.8) and i < int(len(df)*0.9)):\n",
    "        df_val.append(df[i])\n",
    "      else:\n",
    "        df_test.append(df[i])\n",
    "    return df_train, df_val, df_test\n",
    "\n",
    "df_res_train, df_res_val, df_res_test = train_val_test_split(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wnf2v-yh9cEz"
   },
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def get_list_tokens(string):\n",
    "  sentence_split=nltk.tokenize.sent_tokenize(string)    \n",
    "  list_tokens=[]\n",
    "  for sentence in sentence_split:\n",
    "    list_tokens_sentence=nltk.tokenize.word_tokenize(sentence)\n",
    "    for token in list_tokens_sentence:\n",
    "      list_tokens.append(lemmatizer.lemmatize(token).lower())\n",
    "  return list_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Bl_DJUj9cE4"
   },
   "outputs": [],
   "source": [
    "stopwords=set(nltk.corpus.stopwords.words('english'))\n",
    "stopwords.add(\".\")\n",
    "stopwords.add(\",\")\n",
    "stopwords.add(\"--\")\n",
    "stopwords.add(\"``\")\n",
    "stopwords.add('#')\n",
    "stopwords.add('@')\n",
    "stopwords.add(':')\n",
    "stopwords.add('!')\n",
    "stopwords.add('?')\n",
    "stopwords.add(\"'s\")\n",
    "stopwords.add(\"'\")\n",
    "stopwords.add('...')\n",
    "stopwords.add('&')\n",
    "stopwords.add(\"â€™\")\n",
    "stopwords.add(\"-\")\n",
    "stopwords.add(\";\")\n",
    "stopwords.add(\"/\")\n",
    "stopwords.add(\">\")\n",
    "stopwords.add(\"<\")\n",
    "stopwords.add(\"br\")\n",
    "stopwords.add(\")\")\n",
    "stopwords.add(\"(\")\n",
    "stopwords.add(\"''\")\n",
    "stopwords.add(\"n't\")\n",
    "stopwords.add(\"wa\")\n",
    "stopwords.add(\"$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bi_bN1pI9cE7"
   },
   "outputs": [],
   "source": [
    "def get_vocabulary(df_train):\n",
    "    dict_word_freq={}                  \n",
    "    for i in range(0,len(df_train)):\n",
    "      sentence_tokens=get_list_tokens(df_train[i][0])\n",
    "      for word in sentence_tokens:\n",
    "        if word in stopwords: \n",
    "          continue\n",
    "        if word not in dict_word_freq: \n",
    "          dict_word_freq[word]=1\n",
    "        else: \n",
    "          dict_word_freq[word]+=1\n",
    "\n",
    "    sorted_list = sorted(dict_word_freq.items(), key=operator.itemgetter(1), reverse=True)[:300]\n",
    "    vocabulary=[]\n",
    "    for word,frequency in sorted_list:\n",
    "      vocabulary.append(word)\n",
    "    \n",
    "    return vocabulary \n",
    "\n",
    "\n",
    "def get_vector_text(list_vocab,string):\n",
    "  vector_text=np.zeros(len(list_vocab))\n",
    "  list_tokens_string=get_list_tokens(string)   \n",
    "  for i, word in enumerate(list_vocab):\n",
    "    if word in list_tokens_string:\n",
    "      vector_text[i]=list_tokens_string.count(word)\n",
    "  return vector_text\n",
    "\n",
    "def num_long_words(string):\n",
    "  count=0\n",
    "  words=string.split(\" \")\n",
    "  for  word in words:\n",
    "    if len(word)>5:\n",
    "      count+=1\n",
    "  return count\n",
    "\n",
    "def num_sentences(string):\n",
    "  sentences=string.split(\".\")\n",
    "  return len(sentences)\n",
    "\n",
    "\n",
    "def num_repeated_words(string):\n",
    "  unique_words=set()\n",
    "  count=0\n",
    "  punct=[',','.','?','!',\"'\",'\"',';',':']\n",
    "  words=string.split(\" \")\n",
    "  for word in words:\n",
    "    word=word.lower()\n",
    "    for i in range(0,len(punct)):\n",
    "      word=word.replace(punct[i],'')\n",
    "    if word in unique_words:\n",
    "      count+=1\n",
    "    else:\n",
    "      unique_words.add(word)\n",
    "\n",
    "  return count\n",
    "\n",
    "\n",
    "\n",
    "def total_most_used(string,vocabulary):\n",
    "  count=0\n",
    "  vector=get_vector_text(vocabulary,string)\n",
    "  for i in range(0,len(vector)):\n",
    "    count+=int(vector[i])\n",
    "  return count\n",
    "\n",
    "\n",
    "def text2vec(df,vocabulary):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(0,len(df)):\n",
    "        text=df[i][0]\n",
    "        data_vector=get_vector_text(vocabulary,text)\n",
    "        feat1=np.insert(data_vector,0,num_long_words(text))\n",
    "        feat2=np.insert(feat1,0,num_sentences(text))\n",
    "        feat3=np.insert(feat2,0,num_repeated_words(text))\n",
    "        feat4=np.insert(feat3,0,total_most_used(text,vocabulary))\n",
    "        X.append(feat4)\n",
    "        Y.append(df[i][1])\n",
    "    return np.asarray(X, dtype=np.float), np.asarray(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# construct the feature vectors and label vectors, and standardize the feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b6SLrjNS9cFQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def standarize(X_train, X_val, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train, X_val, X_test\n",
    "\n",
    "\n",
    "def preprocess(df_train, df_val, df_test, std=True):\n",
    "    \n",
    "    vocabulary=get_vocabulary(df_train)\n",
    "    \n",
    "    X_train, Y_train = text2vec(df_train,vocabulary)\n",
    "    X_val, Y_val = text2vec(df_val,vocabulary)\n",
    "    X_test, Y_test = text2vec(df_test,vocabulary)\n",
    "    if std:\n",
    "        X_train, X_val, X_test = standarize(X_train, X_val, X_test)\n",
    "    \n",
    "    return X_train, Y_train, X_val, Y_val, X_test, Y_test\n",
    "\n",
    "X_res_train, Y_res_train, X_res_val, Y_res_val, X_res_test, Y_res_test = preprocess(df_res_train, df_res_val, df_res_test)\n",
    "#feature order (from first to last in the numpy array):\n",
    "#total uses of most used words; num repeated words; num sentences; num long words; \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC     \n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "\n",
    "def train_model(X_train, Y_train):\n",
    "    clf = SVC(gamma='auto')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    return clf\n",
    "\n",
    "def predict_and_evaluation(X_train, Y_train, X_val, Y_val, X_test, Y_test, clf):\n",
    "    pred_train = clf.predict(X_train)\n",
    "    pred_val = clf.predict(X_val)\n",
    "    pred_test = clf.predict(X_test)\n",
    "    acc_train = clf.score(X_train, Y_train)\n",
    "    acc_val = clf.score(X_val, Y_val)\n",
    "    acc_test = clf.score(X_test, Y_test)\n",
    "    return pred_train, pred_val, pred_test, acc_train, acc_val, acc_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.990625 0.7948717948717948 0.7804878048780488\n"
     ]
    }
   ],
   "source": [
    "clf_res = train_model(X_res_train, Y_res_train)\n",
    "pred_res_train_svc, pred_res_val_svc, pred_res_test_svc, acc_res_train_svc, acc_res_val_svc, acc_res_test_svc = \\\n",
    "predict_and_evaluation(X_res_train, Y_res_train, X_res_val, Y_res_val, X_res_test, Y_res_test, clf_res)\n",
    "print(acc_res_train_svc, acc_res_val_svc, acc_res_test_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBDT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbdt = GradientBoostingClassifier()\n",
    "gbdt.fit(X_res_train,Y_res_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[23  4]\n",
      " [ 3 11]]\n",
      "Accuracy: 0.8292682926829268\n",
      "Accuracy: 0.8205128205128205\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = bayes.predict(X_res_val)\n",
    "y_test_pred = gbdt.predict(X_res_test)\n",
    "print(\"confusion matrix:\", metrics.confusion_matrix(Y_res_test, y_test_pred))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(Y_res_test, y_test_pred))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(Y_res_val,y_val_pred ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8717948717948718\n",
      "0.8780487804878049\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "text_classifier = RandomForestClassifier(n_estimators=100, random_state=0) \n",
    "text_classifier.fit(X_res_train,Y_res_train)\n",
    "y_valid_pred=text_classifier.predict(X_res_val)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_res_val,y_valid_pred))\n",
    "y_test_pred=text_classifier.predict(X_res_test)\n",
    "print(accuracy_score(Y_res_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "x_n_res=[]\n",
    "y_n_res=[]\n",
    "x_n_res.extend(X_res_train)\n",
    "y_n_res.extend(Y_res_train)\n",
    "x_n_res.extend(X_res_val)\n",
    "y_n_res.extend(Y_res_val)\n",
    "x_n_res=np.asarray(x_n_res)\n",
    "y_n_res=np.asarray(y_n_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323 samples, validate on 36 samples\n",
      "Epoch 1/100\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 0.7883 - accuracy: 0.4737 - val_loss: 0.8396 - val_accuracy: 0.4444\n",
      "Epoch 2/100\n",
      "323/323 [==============================] - 0s 235us/sample - loss: 0.6957 - accuracy: 0.5573 - val_loss: 0.7806 - val_accuracy: 0.4444\n",
      "Epoch 3/100\n",
      "323/323 [==============================] - 0s 229us/sample - loss: 0.6279 - accuracy: 0.6347 - val_loss: 0.7145 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "323/323 [==============================] - 0s 269us/sample - loss: 0.5784 - accuracy: 0.6966 - val_loss: 0.7075 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "323/323 [==============================] - 0s 201us/sample - loss: 0.5292 - accuracy: 0.7647 - val_loss: 0.6548 - val_accuracy: 0.6944\n",
      "Epoch 6/100\n",
      "323/323 [==============================] - 0s 232us/sample - loss: 0.4914 - accuracy: 0.7833 - val_loss: 0.6293 - val_accuracy: 0.7222\n",
      "Epoch 7/100\n",
      "323/323 [==============================] - 0s 210us/sample - loss: 0.4557 - accuracy: 0.8204 - val_loss: 0.6313 - val_accuracy: 0.6944\n",
      "Epoch 8/100\n",
      "323/323 [==============================] - 0s 204us/sample - loss: 0.4240 - accuracy: 0.8452 - val_loss: 0.6058 - val_accuracy: 0.6944\n",
      "Epoch 9/100\n",
      "323/323 [==============================] - 0s 256us/sample - loss: 0.3946 - accuracy: 0.8700 - val_loss: 0.5891 - val_accuracy: 0.7222\n",
      "Epoch 10/100\n",
      "323/323 [==============================] - 0s 216us/sample - loss: 0.3680 - accuracy: 0.8947 - val_loss: 0.5641 - val_accuracy: 0.7778\n",
      "Epoch 11/100\n",
      "323/323 [==============================] - 0s 287us/sample - loss: 0.3437 - accuracy: 0.9195 - val_loss: 0.5520 - val_accuracy: 0.7222\n",
      "Epoch 12/100\n",
      "323/323 [==============================] - 0s 275us/sample - loss: 0.3215 - accuracy: 0.9319 - val_loss: 0.5398 - val_accuracy: 0.8056\n",
      "Epoch 13/100\n",
      "323/323 [==============================] - 0s 241us/sample - loss: 0.3005 - accuracy: 0.9474 - val_loss: 0.5267 - val_accuracy: 0.7778\n",
      "Epoch 14/100\n",
      "323/323 [==============================] - 0s 225us/sample - loss: 0.2831 - accuracy: 0.9474 - val_loss: 0.5205 - val_accuracy: 0.7778\n",
      "Epoch 15/100\n",
      "323/323 [==============================] - 0s 188us/sample - loss: 0.2653 - accuracy: 0.9567 - val_loss: 0.5160 - val_accuracy: 0.8056\n",
      "Epoch 16/100\n",
      "323/323 [==============================] - 0s 176us/sample - loss: 0.2485 - accuracy: 0.9690 - val_loss: 0.5002 - val_accuracy: 0.8056\n",
      "Epoch 17/100\n",
      "323/323 [==============================] - 0s 343us/sample - loss: 0.2330 - accuracy: 0.9659 - val_loss: 0.4948 - val_accuracy: 0.8056\n",
      "Epoch 18/100\n",
      "323/323 [==============================] - 0s 219us/sample - loss: 0.2192 - accuracy: 0.9721 - val_loss: 0.4865 - val_accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "323/323 [==============================] - 0s 235us/sample - loss: 0.2060 - accuracy: 0.9814 - val_loss: 0.4893 - val_accuracy: 0.8056\n",
      "Epoch 20/100\n",
      "323/323 [==============================] - 0s 256us/sample - loss: 0.1941 - accuracy: 0.9752 - val_loss: 0.4795 - val_accuracy: 0.7778\n",
      "Epoch 21/100\n",
      "323/323 [==============================] - 0s 241us/sample - loss: 0.1812 - accuracy: 0.9876 - val_loss: 0.4707 - val_accuracy: 0.8056\n",
      "Epoch 22/100\n",
      "323/323 [==============================] - 0s 210us/sample - loss: 0.1702 - accuracy: 0.9907 - val_loss: 0.4742 - val_accuracy: 0.7778\n",
      "Epoch 23/100\n",
      "323/323 [==============================] - 0s 232us/sample - loss: 0.1610 - accuracy: 0.9907 - val_loss: 0.4685 - val_accuracy: 0.7778\n",
      "Epoch 24/100\n",
      "323/323 [==============================] - 0s 299us/sample - loss: 0.1518 - accuracy: 0.9907 - val_loss: 0.4595 - val_accuracy: 0.8056\n",
      "Epoch 25/100\n",
      "323/323 [==============================] - 0s 253us/sample - loss: 0.1428 - accuracy: 0.9938 - val_loss: 0.4575 - val_accuracy: 0.8056\n",
      "Epoch 26/100\n",
      "323/323 [==============================] - 0s 244us/sample - loss: 0.1348 - accuracy: 0.9907 - val_loss: 0.4547 - val_accuracy: 0.8056\n",
      "Epoch 27/100\n",
      "323/323 [==============================] - 0s 235us/sample - loss: 0.1271 - accuracy: 0.9938 - val_loss: 0.4523 - val_accuracy: 0.8056\n",
      "Epoch 28/100\n",
      "323/323 [==============================] - 0s 207us/sample - loss: 0.1204 - accuracy: 0.9938 - val_loss: 0.4490 - val_accuracy: 0.8056\n",
      "Epoch 29/100\n",
      "323/323 [==============================] - 0s 293us/sample - loss: 0.1140 - accuracy: 0.9969 - val_loss: 0.4474 - val_accuracy: 0.8056\n",
      "Epoch 30/100\n",
      "323/323 [==============================] - 0s 284us/sample - loss: 0.1082 - accuracy: 0.9969 - val_loss: 0.4413 - val_accuracy: 0.8056\n",
      "Epoch 31/100\n",
      "323/323 [==============================] - 0s 266us/sample - loss: 0.1029 - accuracy: 0.9969 - val_loss: 0.4353 - val_accuracy: 0.8056\n",
      "Epoch 32/100\n",
      "323/323 [==============================] - 0s 337us/sample - loss: 0.0975 - accuracy: 0.9969 - val_loss: 0.4403 - val_accuracy: 0.8056\n",
      "Epoch 33/100\n",
      "323/323 [==============================] - 0s 210us/sample - loss: 0.0923 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.8056\n",
      "Epoch 34/100\n",
      "323/323 [==============================] - 0s 235us/sample - loss: 0.0879 - accuracy: 0.9969 - val_loss: 0.4373 - val_accuracy: 0.8056\n",
      "Epoch 35/100\n",
      "323/323 [==============================] - 0s 222us/sample - loss: 0.0832 - accuracy: 1.0000 - val_loss: 0.4305 - val_accuracy: 0.8056\n",
      "Epoch 36/100\n",
      "323/323 [==============================] - 0s 262us/sample - loss: 0.0792 - accuracy: 1.0000 - val_loss: 0.4275 - val_accuracy: 0.8056\n",
      "Epoch 37/100\n",
      "323/323 [==============================] - 0s 256us/sample - loss: 0.0752 - accuracy: 1.0000 - val_loss: 0.4282 - val_accuracy: 0.8056\n",
      "Epoch 38/100\n",
      "323/323 [==============================] - 0s 306us/sample - loss: 0.0718 - accuracy: 1.0000 - val_loss: 0.4232 - val_accuracy: 0.8056\n",
      "Epoch 39/100\n",
      "323/323 [==============================] - 0s 247us/sample - loss: 0.0684 - accuracy: 1.0000 - val_loss: 0.4214 - val_accuracy: 0.8056\n",
      "Epoch 40/100\n",
      "323/323 [==============================] - 0s 225us/sample - loss: 0.0654 - accuracy: 1.0000 - val_loss: 0.4215 - val_accuracy: 0.8056\n",
      "Epoch 41/100\n",
      "323/323 [==============================] - 0s 213us/sample - loss: 0.0626 - accuracy: 1.0000 - val_loss: 0.4232 - val_accuracy: 0.8333\n",
      "Epoch 42/100\n",
      "323/323 [==============================] - 0s 207us/sample - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.4275 - val_accuracy: 0.8056\n",
      "Epoch 43/100\n",
      "323/323 [==============================] - 0s 204us/sample - loss: 0.0571 - accuracy: 1.0000 - val_loss: 0.4273 - val_accuracy: 0.8056\n",
      "Epoch 44/100\n",
      "323/323 [==============================] - 0s 228us/sample - loss: 0.0547 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.8056\n",
      "Epoch 45/100\n",
      "323/323 [==============================] - 0s 210us/sample - loss: 0.0525 - accuracy: 1.0000 - val_loss: 0.4218 - val_accuracy: 0.8056\n",
      "Epoch 46/100\n",
      "323/323 [==============================] - 0s 207us/sample - loss: 0.0507 - accuracy: 1.0000 - val_loss: 0.4295 - val_accuracy: 0.8056\n",
      "Epoch 47/100\n",
      "323/323 [==============================] - 0s 201us/sample - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.8056\n",
      "Epoch 48/100\n",
      "323/323 [==============================] - 0s 225us/sample - loss: 0.0468 - accuracy: 1.0000 - val_loss: 0.4245 - val_accuracy: 0.8333\n",
      "Epoch 49/100\n",
      "323/323 [==============================] - 0s 207us/sample - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.4269 - val_accuracy: 0.8056\n",
      "Epoch 50/100\n",
      "323/323 [==============================] - 0s 222us/sample - loss: 0.0433 - accuracy: 1.0000 - val_loss: 0.4293 - val_accuracy: 0.8056\n",
      "Epoch 51/100\n",
      "323/323 [==============================] - 0s 210us/sample - loss: 0.0418 - accuracy: 1.0000 - val_loss: 0.4255 - val_accuracy: 0.8056\n",
      "Epoch 52/100\n",
      "323/323 [==============================] - 0s 216us/sample - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.4258 - val_accuracy: 0.8333\n",
      "Epoch 53/100\n",
      "323/323 [==============================] - 0s 204us/sample - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.4315 - val_accuracy: 0.8056\n",
      "Epoch 54/100\n",
      "323/323 [==============================] - 0s 204us/sample - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.4303 - val_accuracy: 0.8056\n",
      "Epoch 55/100\n",
      "323/323 [==============================] - 0s 222us/sample - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.4331 - val_accuracy: 0.8056\n",
      "Epoch 56/100\n",
      "323/323 [==============================] - 0s 272us/sample - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.4299 - val_accuracy: 0.8056\n",
      "Epoch 57/100\n",
      "323/323 [==============================] - 0s 333us/sample - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.4271 - val_accuracy: 0.8333\n",
      "Epoch 58/100\n",
      "323/323 [==============================] - 0s 247us/sample - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.4272 - val_accuracy: 0.8333\n",
      "Epoch 59/100\n",
      "323/323 [==============================] - 0s 306us/sample - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.4225 - val_accuracy: 0.8333\n",
      "Epoch 60/100\n",
      "323/323 [==============================] - 0s 281us/sample - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.4246 - val_accuracy: 0.8333\n",
      "Epoch 61/100\n",
      "323/323 [==============================] - 0s 241us/sample - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.4235 - val_accuracy: 0.8333\n",
      "Epoch 62/100\n",
      "323/323 [==============================] - 0s 219us/sample - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.4265 - val_accuracy: 0.8333\n",
      "Epoch 63/100\n",
      "323/323 [==============================] - 0s 222us/sample - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.4284 - val_accuracy: 0.8333\n",
      "Epoch 64/100\n",
      "323/323 [==============================] - 0s 204us/sample - loss: 0.0269 - accuracy: 1.0000 - val_loss: 0.4280 - val_accuracy: 0.8333\n",
      "Epoch 65/100\n",
      "323/323 [==============================] - 0s 204us/sample - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.4267 - val_accuracy: 0.8333\n",
      "Epoch 66/100\n",
      "323/323 [==============================] - 0s 216us/sample - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.4286 - val_accuracy: 0.8333\n",
      "Epoch 67/100\n",
      "323/323 [==============================] - 0s 284us/sample - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.4276 - val_accuracy: 0.8333\n",
      "Epoch 68/100\n",
      "323/323 [==============================] - 0s 309us/sample - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.4271 - val_accuracy: 0.8333\n",
      "Epoch 69/100\n",
      "323/323 [==============================] - 0s 275us/sample - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.4250 - val_accuracy: 0.8333\n",
      "Epoch 70/100\n",
      "323/323 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 1.00 - 0s 213us/sample - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.4255 - val_accuracy: 0.8333\n",
      "Epoch 71/100\n",
      "323/323 [==============================] - 0s 201us/sample - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.4286 - val_accuracy: 0.8333\n",
      "Epoch 72/100\n",
      "323/323 [==============================] - 0s 377us/sample - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.4383 - val_accuracy: 0.8333\n",
      "Epoch 73/100\n",
      "323/323 [==============================] - 0s 531us/sample - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.4418 - val_accuracy: 0.8333\n",
      "Epoch 74/100\n",
      "323/323 [==============================] - 0s 290us/sample - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.8333\n",
      "Epoch 75/100\n",
      "323/323 [==============================] - 0s 281us/sample - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.4416 - val_accuracy: 0.8333\n",
      "Epoch 76/100\n",
      "323/323 [==============================] - 0s 472us/sample - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.4389 - val_accuracy: 0.8333\n",
      "Epoch 77/100\n",
      "323/323 [==============================] - 0s 216us/sample - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.4395 - val_accuracy: 0.8333\n",
      "Epoch 78/100\n",
      "323/323 [==============================] - 0s 259us/sample - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.4385 - val_accuracy: 0.8333\n",
      "Epoch 79/100\n",
      "323/323 [==============================] - 0s 290us/sample - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.4402 - val_accuracy: 0.8333\n",
      "Epoch 80/100\n",
      "323/323 [==============================] - 0s 219us/sample - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.4397 - val_accuracy: 0.8333\n",
      "Epoch 81/100\n",
      "323/323 [==============================] - 0s 247us/sample - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.8333\n",
      "Epoch 82/100\n",
      "323/323 [==============================] - 0s 244us/sample - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.4398 - val_accuracy: 0.8333\n",
      "Epoch 83/100\n",
      "323/323 [==============================] - 0s 235us/sample - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.4405 - val_accuracy: 0.8333\n",
      "Epoch 84/100\n",
      "323/323 [==============================] - 0s 398us/sample - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.4401 - val_accuracy: 0.8333\n",
      "Epoch 85/100\n",
      "323/323 [==============================] - 0s 500us/sample - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.4429 - val_accuracy: 0.8333\n",
      "Epoch 86/100\n",
      "323/323 [==============================] - 0s 500us/sample - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.4413 - val_accuracy: 0.8333\n",
      "Epoch 87/100\n",
      "323/323 [==============================] - 0s 516us/sample - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.4428 - val_accuracy: 0.8333\n",
      "Epoch 88/100\n",
      "323/323 [==============================] - 0s 682us/sample - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.4430 - val_accuracy: 0.8333\n",
      "Epoch 89/100\n",
      "323/323 [==============================] - 0s 358us/sample - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.4430 - val_accuracy: 0.8333\n",
      "Epoch 90/100\n",
      "323/323 [==============================] - 0s 278us/sample - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.4433 - val_accuracy: 0.8333\n",
      "Epoch 91/100\n",
      "323/323 [==============================] - 0s 383us/sample - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.4436 - val_accuracy: 0.8333\n",
      "Epoch 92/100\n",
      "323/323 [==============================] - 0s 309us/sample - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.4472 - val_accuracy: 0.8333\n",
      "Epoch 93/100\n",
      "323/323 [==============================] - 0s 309us/sample - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.4472 - val_accuracy: 0.8333\n",
      "Epoch 94/100\n",
      "323/323 [==============================] - 0s 371us/sample - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.4431 - val_accuracy: 0.8333\n",
      "Epoch 95/100\n",
      "323/323 [==============================] - 0s 414us/sample - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.4483 - val_accuracy: 0.8333\n",
      "Epoch 96/100\n",
      "323/323 [==============================] - 0s 309us/sample - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.4472 - val_accuracy: 0.8333\n",
      "Epoch 97/100\n",
      "323/323 [==============================] - 0s 420us/sample - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 98/100\n",
      "323/323 [==============================] - 0s 531us/sample - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.4535 - val_accuracy: 0.8333\n",
      "Epoch 99/100\n",
      "323/323 [==============================] - 0s 970us/sample - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 100/100\n",
      "323/323 [==============================] - 0s 482us/sample - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.4515 - val_accuracy: 0.8333\n"
     ]
    }
   ],
   "source": [
    "# Activation function:RELU\n",
    "from numpy.random import seed\n",
    "seed(0)\n",
    "tf.random.set_seed(0)    \n",
    "relu_res = keras.models.Sequential()\n",
    "#model.add(keras.layers.Flatten(input_shape=[len(X_res_train[0])]))\n",
    "relu_res.add(keras.layers.Dense(300,input_dim=X_res_train.shape[1],activation=\"relu\"))   \n",
    "relu_res.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "relu_res.add(keras.layers.Dense(2, activation=\"softmax\"))\n",
    "relu_res.compile(loss = \"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics = [\"accuracy\"])\n",
    "relu_res_history = relu_res.fit(x_n_res, y_n_res, epochs = 100, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 414us/sample - loss: 0.4038 - accuracy: 0.8537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4038320954253034, 0.85365856]"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu_res.evaluate(X_res_test, Y_res_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323 samples, validate on 36 samples\n",
      "Epoch 1/100\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 0.7613 - accuracy: 0.5449 - val_loss: 0.7891 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "323/323 [==============================] - 0s 488us/sample - loss: 0.6500 - accuracy: 0.6347 - val_loss: 0.7091 - val_accuracy: 0.6111\n",
      "Epoch 3/100\n",
      "323/323 [==============================] - 0s 469us/sample - loss: 0.5684 - accuracy: 0.6842 - val_loss: 0.6578 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "323/323 [==============================] - 0s 333us/sample - loss: 0.5074 - accuracy: 0.7678 - val_loss: 0.6180 - val_accuracy: 0.6944\n",
      "Epoch 5/100\n",
      "323/323 [==============================] - 0s 361us/sample - loss: 0.4563 - accuracy: 0.8080 - val_loss: 0.5898 - val_accuracy: 0.7222\n",
      "Epoch 6/100\n",
      "323/323 [==============================] - 0s 364us/sample - loss: 0.4161 - accuracy: 0.8390 - val_loss: 0.5619 - val_accuracy: 0.7222\n",
      "Epoch 7/100\n",
      "323/323 [==============================] - 0s 278us/sample - loss: 0.3798 - accuracy: 0.8669 - val_loss: 0.5528 - val_accuracy: 0.7500\n",
      "Epoch 8/100\n",
      "323/323 [==============================] - 0s 185us/sample - loss: 0.3484 - accuracy: 0.8793 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
      "Epoch 9/100\n",
      "323/323 [==============================] - 0s 232us/sample - loss: 0.3216 - accuracy: 0.9009 - val_loss: 0.5192 - val_accuracy: 0.7222\n",
      "Epoch 10/100\n",
      "323/323 [==============================] - 0s 312us/sample - loss: 0.2954 - accuracy: 0.9133 - val_loss: 0.5058 - val_accuracy: 0.7778\n",
      "Epoch 11/100\n",
      "323/323 [==============================] - 0s 185us/sample - loss: 0.2719 - accuracy: 0.9381 - val_loss: 0.4938 - val_accuracy: 0.8056\n",
      "Epoch 12/100\n",
      "323/323 [==============================] - 0s 216us/sample - loss: 0.2526 - accuracy: 0.9443 - val_loss: 0.4793 - val_accuracy: 0.7778\n",
      "Epoch 13/100\n",
      "323/323 [==============================] - 0s 191us/sample - loss: 0.2346 - accuracy: 0.9505 - val_loss: 0.4720 - val_accuracy: 0.8056\n",
      "Epoch 14/100\n",
      "323/323 [==============================] - 0s 442us/sample - loss: 0.2190 - accuracy: 0.9505 - val_loss: 0.4727 - val_accuracy: 0.7778\n",
      "Epoch 15/100\n",
      "323/323 [==============================] - 0s 364us/sample - loss: 0.2037 - accuracy: 0.9690 - val_loss: 0.4694 - val_accuracy: 0.7778\n",
      "Epoch 16/100\n",
      "323/323 [==============================] - 0s 312us/sample - loss: 0.1899 - accuracy: 0.9752 - val_loss: 0.4614 - val_accuracy: 0.7500\n",
      "Epoch 17/100\n",
      "323/323 [==============================] - 0s 173us/sample - loss: 0.1779 - accuracy: 0.9752 - val_loss: 0.4595 - val_accuracy: 0.7500\n",
      "Epoch 18/100\n",
      "323/323 [==============================] - 0s 204us/sample - loss: 0.1664 - accuracy: 0.9814 - val_loss: 0.4565 - val_accuracy: 0.7778\n",
      "Epoch 19/100\n",
      "323/323 [==============================] - 0s 182us/sample - loss: 0.1562 - accuracy: 0.9845 - val_loss: 0.4578 - val_accuracy: 0.7500\n",
      "Epoch 20/100\n",
      "323/323 [==============================] - 0s 182us/sample - loss: 0.1460 - accuracy: 0.9907 - val_loss: 0.4535 - val_accuracy: 0.8056\n",
      "Epoch 21/100\n",
      "323/323 [==============================] - 0s 204us/sample - loss: 0.1374 - accuracy: 0.9876 - val_loss: 0.4513 - val_accuracy: 0.7778\n",
      "Epoch 22/100\n",
      "323/323 [==============================] - 0s 309us/sample - loss: 0.1295 - accuracy: 0.9876 - val_loss: 0.4502 - val_accuracy: 0.8056\n",
      "Epoch 23/100\n",
      "323/323 [==============================] - 0s 275us/sample - loss: 0.1219 - accuracy: 0.9876 - val_loss: 0.4478 - val_accuracy: 0.8056\n",
      "Epoch 24/100\n",
      "323/323 [==============================] - 0s 488us/sample - loss: 0.1151 - accuracy: 0.9876 - val_loss: 0.4509 - val_accuracy: 0.7778\n",
      "Epoch 25/100\n",
      "323/323 [==============================] - 0s 232us/sample - loss: 0.1088 - accuracy: 0.9907 - val_loss: 0.4504 - val_accuracy: 0.7778\n",
      "Epoch 26/100\n",
      "323/323 [==============================] - 0s 235us/sample - loss: 0.1029 - accuracy: 0.9938 - val_loss: 0.4498 - val_accuracy: 0.7778\n",
      "Epoch 27/100\n",
      "323/323 [==============================] - 0s 324us/sample - loss: 0.0973 - accuracy: 0.9938 - val_loss: 0.4507 - val_accuracy: 0.7778\n",
      "Epoch 28/100\n",
      "323/323 [==============================] - 0s 219us/sample - loss: 0.0924 - accuracy: 0.9938 - val_loss: 0.4521 - val_accuracy: 0.7778\n",
      "Epoch 29/100\n",
      "323/323 [==============================] - 0s 213us/sample - loss: 0.0876 - accuracy: 0.9969 - val_loss: 0.4514 - val_accuracy: 0.7778\n",
      "Epoch 30/100\n",
      "323/323 [==============================] - 0s 195us/sample - loss: 0.0833 - accuracy: 0.9969 - val_loss: 0.4527 - val_accuracy: 0.7778\n",
      "Epoch 31/100\n",
      "323/323 [==============================] - 0s 284us/sample - loss: 0.0794 - accuracy: 0.9969 - val_loss: 0.4519 - val_accuracy: 0.7778\n",
      "Epoch 32/100\n",
      "323/323 [==============================] - 0s 241us/sample - loss: 0.0756 - accuracy: 1.0000 - val_loss: 0.4533 - val_accuracy: 0.7778\n",
      "Epoch 33/100\n",
      "323/323 [==============================] - 0s 238us/sample - loss: 0.0721 - accuracy: 1.0000 - val_loss: 0.4541 - val_accuracy: 0.7778\n",
      "Epoch 34/100\n",
      "323/323 [==============================] - 0s 281us/sample - loss: 0.0687 - accuracy: 1.0000 - val_loss: 0.4554 - val_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "323/323 [==============================] - 0s 284us/sample - loss: 0.0652 - accuracy: 1.0000 - val_loss: 0.4540 - val_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "323/323 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 1.00 - 0s 259us/sample - loss: 0.0623 - accuracy: 1.0000 - val_loss: 0.4523 - val_accuracy: 0.8611\n",
      "Epoch 37/100\n",
      "323/323 [==============================] - 0s 287us/sample - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.4534 - val_accuracy: 0.8611\n",
      "Epoch 38/100\n",
      "323/323 [==============================] - 0s 219us/sample - loss: 0.0571 - accuracy: 1.0000 - val_loss: 0.4499 - val_accuracy: 0.8611\n",
      "Epoch 39/100\n",
      "323/323 [==============================] - 0s 198us/sample - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
      "Epoch 40/100\n",
      "323/323 [==============================] - 0s 188us/sample - loss: 0.0523 - accuracy: 1.0000 - val_loss: 0.4533 - val_accuracy: 0.8333\n",
      "Epoch 41/100\n",
      "323/323 [==============================] - 0s 185us/sample - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.4560 - val_accuracy: 0.8333\n",
      "Epoch 42/100\n",
      "323/323 [==============================] - 0s 228us/sample - loss: 0.0484 - accuracy: 1.0000 - val_loss: 0.4570 - val_accuracy: 0.8333\n",
      "Epoch 43/100\n",
      "323/323 [==============================] - 0s 198us/sample - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.4585 - val_accuracy: 0.8333\n",
      "Epoch 44/100\n",
      "323/323 [==============================] - 0s 201us/sample - loss: 0.0448 - accuracy: 1.0000 - val_loss: 0.4606 - val_accuracy: 0.8333\n",
      "Epoch 45/100\n",
      "323/323 [==============================] - 0s 222us/sample - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.4678 - val_accuracy: 0.8333\n",
      "Epoch 46/100\n",
      "323/323 [==============================] - 0s 191us/sample - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.4704 - val_accuracy: 0.8333\n",
      "Epoch 47/100\n",
      "323/323 [==============================] - 0s 173us/sample - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.4715 - val_accuracy: 0.8333\n",
      "Epoch 48/100\n",
      "323/323 [==============================] - 0s 157us/sample - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.4717 - val_accuracy: 0.8333\n",
      "Epoch 49/100\n",
      "323/323 [==============================] - 0s 154us/sample - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.4726 - val_accuracy: 0.8333\n",
      "Epoch 50/100\n",
      "323/323 [==============================] - 0s 173us/sample - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.4728 - val_accuracy: 0.8333\n",
      "Epoch 51/100\n",
      "323/323 [==============================] - 0s 170us/sample - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.4759 - val_accuracy: 0.8333\n",
      "Epoch 52/100\n",
      "323/323 [==============================] - 0s 176us/sample - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.4776 - val_accuracy: 0.8333\n",
      "Epoch 53/100\n",
      "323/323 [==============================] - 0s 167us/sample - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.4798 - val_accuracy: 0.8333\n",
      "Epoch 54/100\n",
      "323/323 [==============================] - 0s 164us/sample - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.4820 - val_accuracy: 0.8333\n",
      "Epoch 55/100\n",
      "323/323 [==============================] - 0s 157us/sample - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.4830 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "323/323 [==============================] - 0s 182us/sample - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.4844 - val_accuracy: 0.8333\n",
      "Epoch 57/100\n",
      "323/323 [==============================] - 0s 188us/sample - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.4863 - val_accuracy: 0.8333\n",
      "Epoch 58/100\n",
      "323/323 [==============================] - 0s 244us/sample - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.4879 - val_accuracy: 0.8333\n",
      "Epoch 59/100\n",
      "323/323 [==============================] - 0s 161us/sample - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.4875 - val_accuracy: 0.8333\n",
      "Epoch 60/100\n",
      "323/323 [==============================] - 0s 188us/sample - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.8333\n",
      "Epoch 61/100\n",
      "323/323 [==============================] - 0s 213us/sample - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.4909 - val_accuracy: 0.8333\n",
      "Epoch 62/100\n",
      "323/323 [==============================] - 0s 173us/sample - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.4927 - val_accuracy: 0.8333\n",
      "Epoch 63/100\n",
      "323/323 [==============================] - 0s 157us/sample - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.4938 - val_accuracy: 0.8333\n",
      "Epoch 64/100\n",
      "323/323 [==============================] - 0s 167us/sample - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.4951 - val_accuracy: 0.8333\n",
      "Epoch 65/100\n",
      "323/323 [==============================] - 0s 157us/sample - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.4966 - val_accuracy: 0.8333\n",
      "Epoch 66/100\n",
      "323/323 [==============================] - 0s 161us/sample - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.4979 - val_accuracy: 0.8333\n",
      "Epoch 67/100\n",
      "323/323 [==============================] - 0s 173us/sample - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.4993 - val_accuracy: 0.8333\n",
      "Epoch 68/100\n",
      "323/323 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 1.00 - 0s 164us/sample - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.5002 - val_accuracy: 0.8333\n",
      "Epoch 69/100\n",
      "323/323 [==============================] - 0s 182us/sample - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.4999 - val_accuracy: 0.8333\n",
      "Epoch 70/100\n",
      "323/323 [==============================] - 0s 164us/sample - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.5013 - val_accuracy: 0.8333\n",
      "Epoch 71/100\n",
      "323/323 [==============================] - 0s 161us/sample - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.8333\n",
      "Epoch 72/100\n",
      "323/323 [==============================] - 0s 167us/sample - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.5047 - val_accuracy: 0.8333\n",
      "Epoch 73/100\n",
      "323/323 [==============================] - 0s 157us/sample - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.5073 - val_accuracy: 0.8333\n",
      "Epoch 74/100\n",
      "323/323 [==============================] - 0s 179us/sample - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.5083 - val_accuracy: 0.8333\n",
      "Epoch 75/100\n",
      "323/323 [==============================] - 0s 161us/sample - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.5106 - val_accuracy: 0.8333\n",
      "Epoch 76/100\n",
      "323/323 [==============================] - 0s 154us/sample - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.5119 - val_accuracy: 0.8333\n",
      "Epoch 77/100\n",
      "323/323 [==============================] - 0s 154us/sample - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.5131 - val_accuracy: 0.8333\n",
      "Epoch 78/100\n",
      "323/323 [==============================] - 0s 176us/sample - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.5145 - val_accuracy: 0.8333\n",
      "Epoch 79/100\n",
      "323/323 [==============================] - 0s 170us/sample - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.5158 - val_accuracy: 0.8333\n",
      "Epoch 80/100\n",
      "323/323 [==============================] - 0s 201us/sample - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.5173 - val_accuracy: 0.8333\n",
      "Epoch 81/100\n",
      "323/323 [==============================] - 0s 204us/sample - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.5193 - val_accuracy: 0.8333\n",
      "Epoch 82/100\n",
      "323/323 [==============================] - 0s 228us/sample - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.5207 - val_accuracy: 0.8333\n",
      "Epoch 83/100\n",
      "323/323 [==============================] - 0s 222us/sample - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.5221 - val_accuracy: 0.8333\n",
      "Epoch 84/100\n",
      "323/323 [==============================] - 0s 241us/sample - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.5235 - val_accuracy: 0.8333\n",
      "Epoch 85/100\n",
      "323/323 [==============================] - 0s 222us/sample - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.5253 - val_accuracy: 0.8333\n",
      "Epoch 86/100\n",
      "323/323 [==============================] - 0s 198us/sample - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.5266 - val_accuracy: 0.8333\n",
      "Epoch 87/100\n",
      "323/323 [==============================] - 0s 179us/sample - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.5280 - val_accuracy: 0.8333\n",
      "Epoch 88/100\n",
      "323/323 [==============================] - 0s 164us/sample - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.5281 - val_accuracy: 0.8333\n",
      "Epoch 89/100\n",
      "323/323 [==============================] - 0s 290us/sample - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.5302 - val_accuracy: 0.8333\n",
      "Epoch 90/100\n",
      "323/323 [==============================] - 0s 293us/sample - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.5312 - val_accuracy: 0.8333\n",
      "Epoch 91/100\n",
      "323/323 [==============================] - 0s 253us/sample - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.5326 - val_accuracy: 0.8333\n",
      "Epoch 92/100\n",
      "323/323 [==============================] - 0s 259us/sample - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.5342 - val_accuracy: 0.8333\n",
      "Epoch 93/100\n",
      "323/323 [==============================] - 0s 296us/sample - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.5356 - val_accuracy: 0.8333\n",
      "Epoch 94/100\n",
      "323/323 [==============================] - 0s 213us/sample - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.5358 - val_accuracy: 0.8333\n",
      "Epoch 95/100\n",
      "323/323 [==============================] - 0s 219us/sample - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.5386 - val_accuracy: 0.8333\n",
      "Epoch 96/100\n",
      "323/323 [==============================] - 0s 253us/sample - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.5388 - val_accuracy: 0.8333\n",
      "Epoch 97/100\n",
      "323/323 [==============================] - 0s 219us/sample - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.5404 - val_accuracy: 0.8333\n",
      "Epoch 98/100\n",
      "323/323 [==============================] - 0s 219us/sample - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.5417 - val_accuracy: 0.8056\n",
      "Epoch 99/100\n",
      "323/323 [==============================] - 0s 315us/sample - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.5426 - val_accuracy: 0.8056\n",
      "Epoch 100/100\n",
      "323/323 [==============================] - 0s 300us/sample - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.5436 - val_accuracy: 0.8056\n"
     ]
    }
   ],
   "source": [
    "#Activation function:Tanh\n",
    "seed(0)\n",
    "tf.random.set_seed(0)   \n",
    "tanh_res = keras.models.Sequential()\n",
    "tanh_res.add(keras.layers.Dense(300,input_dim=X_res_train.shape[1],activation=\"tanh\"))   \n",
    "tanh_res.add(keras.layers.Dense(100, activation=\"tanh\"))\n",
    "tanh_res.add(keras.layers.Dense(2, activation=\"softmax\"))\n",
    "tanh_res.compile(loss = \"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics = [\"accuracy\"])\n",
    "tanh_res_history = tanh_res.fit(x_n_res, y_n_res, epochs = 100, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 341us/sample - loss: 0.5009 - accuracy: 0.8049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5008891879058466, 0.80487806]"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tanh_res.evaluate(X_res_test, Y_res_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323 samples, validate on 36 samples\n",
      "Epoch 1/100\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 0.8073 - accuracy: 0.5108 - val_loss: 0.8779 - val_accuracy: 0.4167\n",
      "Epoch 2/100\n",
      "323/323 [==============================] - 0s 207us/sample - loss: 0.6708 - accuracy: 0.5975 - val_loss: 0.7651 - val_accuracy: 0.5278\n",
      "Epoch 3/100\n",
      "323/323 [==============================] - 0s 266us/sample - loss: 0.5793 - accuracy: 0.6966 - val_loss: 0.6803 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "323/323 [==============================] - 0s 281us/sample - loss: 0.5146 - accuracy: 0.7430 - val_loss: 0.6414 - val_accuracy: 0.7222\n",
      "Epoch 5/100\n",
      "323/323 [==============================] - 0s 300us/sample - loss: 0.4605 - accuracy: 0.8050 - val_loss: 0.5987 - val_accuracy: 0.7778\n",
      "Epoch 6/100\n",
      "323/323 [==============================] - 0s 228us/sample - loss: 0.4212 - accuracy: 0.8297 - val_loss: 0.5664 - val_accuracy: 0.7500\n",
      "Epoch 7/100\n",
      "323/323 [==============================] - 0s 207us/sample - loss: 0.3851 - accuracy: 0.8514 - val_loss: 0.5532 - val_accuracy: 0.7778\n",
      "Epoch 8/100\n",
      "323/323 [==============================] - 0s 222us/sample - loss: 0.3544 - accuracy: 0.8669 - val_loss: 0.5328 - val_accuracy: 0.7222\n",
      "Epoch 9/100\n",
      "323/323 [==============================] - 0s 312us/sample - loss: 0.3271 - accuracy: 0.8854 - val_loss: 0.5143 - val_accuracy: 0.7778\n",
      "Epoch 10/100\n",
      "323/323 [==============================] - 0s 228us/sample - loss: 0.3017 - accuracy: 0.9133 - val_loss: 0.5063 - val_accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "323/323 [==============================] - 0s 213us/sample - loss: 0.2801 - accuracy: 0.9288 - val_loss: 0.4926 - val_accuracy: 0.7500\n",
      "Epoch 12/100\n",
      "323/323 [==============================] - 0s 228us/sample - loss: 0.2614 - accuracy: 0.9350 - val_loss: 0.4802 - val_accuracy: 0.7778\n",
      "Epoch 13/100\n",
      "323/323 [==============================] - 0s 238us/sample - loss: 0.2434 - accuracy: 0.9505 - val_loss: 0.4738 - val_accuracy: 0.7778\n",
      "Epoch 14/100\n",
      "323/323 [==============================] - 0s 303us/sample - loss: 0.2287 - accuracy: 0.9567 - val_loss: 0.4771 - val_accuracy: 0.7778\n",
      "Epoch 15/100\n",
      "323/323 [==============================] - 0s 266us/sample - loss: 0.2149 - accuracy: 0.9536 - val_loss: 0.4677 - val_accuracy: 0.8056\n",
      "Epoch 16/100\n",
      "323/323 [==============================] - 0s 300us/sample - loss: 0.2004 - accuracy: 0.9628 - val_loss: 0.4552 - val_accuracy: 0.8056\n",
      "Epoch 17/100\n",
      "323/323 [==============================] - 0s 318us/sample - loss: 0.1883 - accuracy: 0.9659 - val_loss: 0.4533 - val_accuracy: 0.8056\n",
      "Epoch 18/100\n",
      "323/323 [==============================] - 0s 247us/sample - loss: 0.1772 - accuracy: 0.9628 - val_loss: 0.4461 - val_accuracy: 0.8056\n",
      "Epoch 19/100\n",
      "323/323 [==============================] - 0s 216us/sample - loss: 0.1666 - accuracy: 0.9752 - val_loss: 0.4446 - val_accuracy: 0.8056\n",
      "Epoch 20/100\n",
      "323/323 [==============================] - 0s 346us/sample - loss: 0.1566 - accuracy: 0.9845 - val_loss: 0.4420 - val_accuracy: 0.8056\n",
      "Epoch 21/100\n",
      "323/323 [==============================] - 0s 324us/sample - loss: 0.1470 - accuracy: 0.9876 - val_loss: 0.4377 - val_accuracy: 0.8056\n",
      "Epoch 22/100\n",
      "323/323 [==============================] - 0s 269us/sample - loss: 0.1386 - accuracy: 0.9876 - val_loss: 0.4439 - val_accuracy: 0.8056\n",
      "Epoch 23/100\n",
      "323/323 [==============================] - 0s 340us/sample - loss: 0.1312 - accuracy: 0.9876 - val_loss: 0.4392 - val_accuracy: 0.8056\n",
      "Epoch 24/100\n",
      "323/323 [==============================] - 0s 358us/sample - loss: 0.1239 - accuracy: 0.9876 - val_loss: 0.4355 - val_accuracy: 0.8056\n",
      "Epoch 25/100\n",
      "323/323 [==============================] - 0s 287us/sample - loss: 0.1170 - accuracy: 0.9907 - val_loss: 0.4351 - val_accuracy: 0.8056\n",
      "Epoch 26/100\n",
      "323/323 [==============================] - 0s 219us/sample - loss: 0.1107 - accuracy: 0.9938 - val_loss: 0.4355 - val_accuracy: 0.8056\n",
      "Epoch 27/100\n",
      "323/323 [==============================] - 0s 176us/sample - loss: 0.1047 - accuracy: 0.9938 - val_loss: 0.4347 - val_accuracy: 0.8056\n",
      "Epoch 28/100\n",
      "323/323 [==============================] - 0s 300us/sample - loss: 0.0994 - accuracy: 0.9938 - val_loss: 0.4335 - val_accuracy: 0.8056\n",
      "Epoch 29/100\n",
      "323/323 [==============================] - 0s 346us/sample - loss: 0.0943 - accuracy: 1.0000 - val_loss: 0.4330 - val_accuracy: 0.8056\n",
      "Epoch 30/100\n",
      "323/323 [==============================] - 0s 241us/sample - loss: 0.0898 - accuracy: 1.0000 - val_loss: 0.4308 - val_accuracy: 0.8056\n",
      "Epoch 31/100\n",
      "323/323 [==============================] - 0s 222us/sample - loss: 0.0853 - accuracy: 1.0000 - val_loss: 0.4272 - val_accuracy: 0.8056\n",
      "Epoch 32/100\n",
      "323/323 [==============================] - 0s 272us/sample - loss: 0.0811 - accuracy: 1.0000 - val_loss: 0.4309 - val_accuracy: 0.8056\n",
      "Epoch 33/100\n",
      "323/323 [==============================] - 0s 235us/sample - loss: 0.0772 - accuracy: 1.0000 - val_loss: 0.4277 - val_accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "323/323 [==============================] - 0s 182us/sample - loss: 0.0736 - accuracy: 1.0000 - val_loss: 0.4288 - val_accuracy: 0.8056\n",
      "Epoch 35/100\n",
      "323/323 [==============================] - 0s 185us/sample - loss: 0.0698 - accuracy: 1.0000 - val_loss: 0.4267 - val_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "323/323 [==============================] - 0s 195us/sample - loss: 0.0668 - accuracy: 1.0000 - val_loss: 0.4245 - val_accuracy: 0.8056\n",
      "Epoch 37/100\n",
      "323/323 [==============================] - 0s 333us/sample - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.4254 - val_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "323/323 [==============================] - 0s 442us/sample - loss: 0.0610 - accuracy: 1.0000 - val_loss: 0.4199 - val_accuracy: 0.8333\n",
      "Epoch 39/100\n",
      "323/323 [==============================] - 0s 259us/sample - loss: 0.0583 - accuracy: 1.0000 - val_loss: 0.4214 - val_accuracy: 0.8333\n",
      "Epoch 40/100\n",
      "323/323 [==============================] - 0s 164us/sample - loss: 0.0559 - accuracy: 1.0000 - val_loss: 0.4229 - val_accuracy: 0.8333\n",
      "Epoch 41/100\n",
      "323/323 [==============================] - 0s 182us/sample - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.4274 - val_accuracy: 0.8333\n",
      "Epoch 42/100\n",
      "323/323 [==============================] - 0s 173us/sample - loss: 0.0515 - accuracy: 1.0000 - val_loss: 0.4317 - val_accuracy: 0.8333\n",
      "Epoch 43/100\n",
      "323/323 [==============================] - 0s 293us/sample - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.4325 - val_accuracy: 0.8333\n",
      "Epoch 44/100\n",
      "323/323 [==============================] - 0s 408us/sample - loss: 0.0475 - accuracy: 1.0000 - val_loss: 0.4312 - val_accuracy: 0.8333\n",
      "Epoch 45/100\n",
      "323/323 [==============================] - 0s 173us/sample - loss: 0.0457 - accuracy: 1.0000 - val_loss: 0.4312 - val_accuracy: 0.8056\n",
      "Epoch 46/100\n",
      "323/323 [==============================] - 0s 225us/sample - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.4387 - val_accuracy: 0.8333\n",
      "Epoch 47/100\n",
      "323/323 [==============================] - 0s 244us/sample - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.4398 - val_accuracy: 0.8333\n",
      "Epoch 48/100\n",
      "323/323 [==============================] - 0s 173us/sample - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.4374 - val_accuracy: 0.8333\n",
      "Epoch 49/100\n",
      "323/323 [==============================] - 0s 438us/sample - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.4397 - val_accuracy: 0.8333\n",
      "Epoch 50/100\n",
      "323/323 [==============================] - 0s 204us/sample - loss: 0.0383 - accuracy: 1.0000 - val_loss: 0.4419 - val_accuracy: 0.8333\n",
      "Epoch 51/100\n",
      "323/323 [==============================] - 0s 250us/sample - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.4414 - val_accuracy: 0.8333\n",
      "Epoch 52/100\n",
      "323/323 [==============================] - 0s 225us/sample - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.4432 - val_accuracy: 0.8333\n",
      "Epoch 53/100\n",
      "323/323 [==============================] - 0s 173us/sample - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.4474 - val_accuracy: 0.8333\n",
      "Epoch 54/100\n",
      "323/323 [==============================] - 0s 176us/sample - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.4480 - val_accuracy: 0.8333\n",
      "Epoch 55/100\n",
      "323/323 [==============================] - 0s 173us/sample - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.4504 - val_accuracy: 0.8333\n",
      "Epoch 56/100\n",
      "323/323 [==============================] - 0s 164us/sample - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 57/100\n",
      "323/323 [==============================] - 0s 164us/sample - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.4496 - val_accuracy: 0.8333\n",
      "Epoch 58/100\n",
      "323/323 [==============================] - 0s 176us/sample - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.4502 - val_accuracy: 0.8333\n",
      "Epoch 59/100\n",
      "323/323 [==============================] - 0s 164us/sample - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.4476 - val_accuracy: 0.8333\n",
      "Epoch 60/100\n",
      "323/323 [==============================] - 0s 157us/sample - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.4491 - val_accuracy: 0.8333\n",
      "Epoch 61/100\n",
      "323/323 [==============================] - 0s 182us/sample - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.4498 - val_accuracy: 0.8333\n",
      "Epoch 62/100\n",
      "323/323 [==============================] - 0s 219us/sample - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
      "Epoch 63/100\n",
      "323/323 [==============================] - 0s 195us/sample - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.4543 - val_accuracy: 0.8333\n",
      "Epoch 64/100\n",
      "323/323 [==============================] - 0s 207us/sample - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.4553 - val_accuracy: 0.8333\n",
      "Epoch 65/100\n",
      "323/323 [==============================] - 0s 225us/sample - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.4556 - val_accuracy: 0.8611\n",
      "Epoch 66/100\n",
      "323/323 [==============================] - 0s 253us/sample - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.4576 - val_accuracy: 0.8611\n",
      "Epoch 67/100\n",
      "323/323 [==============================] - 0s 293us/sample - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.4588 - val_accuracy: 0.8333\n",
      "Epoch 68/100\n",
      "323/323 [==============================] - 0s 167us/sample - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.4592 - val_accuracy: 0.8333\n",
      "Epoch 69/100\n",
      "323/323 [==============================] - 0s 188us/sample - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.4592 - val_accuracy: 0.8333\n",
      "Epoch 70/100\n",
      "323/323 [==============================] - 0s 157us/sample - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.4601 - val_accuracy: 0.8333\n",
      "Epoch 71/100\n",
      "323/323 [==============================] - 0s 191us/sample - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.4624 - val_accuracy: 0.8333\n",
      "Epoch 72/100\n",
      "323/323 [==============================] - 0s 195us/sample - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.4688 - val_accuracy: 0.8333\n",
      "Epoch 73/100\n",
      "323/323 [==============================] - 0s 182us/sample - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.4728 - val_accuracy: 0.8333\n",
      "Epoch 74/100\n",
      "323/323 [==============================] - 0s 219us/sample - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.4734 - val_accuracy: 0.8333\n",
      "Epoch 75/100\n",
      "323/323 [==============================] - 0s 306us/sample - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.4764 - val_accuracy: 0.8333\n",
      "Epoch 76/100\n",
      "323/323 [==============================] - 0s 275us/sample - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.4765 - val_accuracy: 0.8333\n",
      "Epoch 77/100\n",
      "323/323 [==============================] - 0s 216us/sample - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.4774 - val_accuracy: 0.8333\n",
      "Epoch 78/100\n",
      "323/323 [==============================] - 0s 216us/sample - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.4782 - val_accuracy: 0.8333\n",
      "Epoch 79/100\n",
      "323/323 [==============================] - 0s 191us/sample - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.4799 - val_accuracy: 0.8333\n",
      "Epoch 80/100\n",
      "323/323 [==============================] - 0s 198us/sample - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.4808 - val_accuracy: 0.8333\n",
      "Epoch 81/100\n",
      "323/323 [==============================] - 0s 201us/sample - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.4823 - val_accuracy: 0.8333\n",
      "Epoch 82/100\n",
      "323/323 [==============================] - 0s 185us/sample - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.4833 - val_accuracy: 0.8333\n",
      "Epoch 83/100\n",
      "323/323 [==============================] - 0s 315us/sample - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.4847 - val_accuracy: 0.8333\n",
      "Epoch 84/100\n",
      "323/323 [==============================] - 0s 262us/sample - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.4858 - val_accuracy: 0.8333\n",
      "Epoch 85/100\n",
      "323/323 [==============================] - 0s 247us/sample - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.4882 - val_accuracy: 0.8333\n",
      "Epoch 86/100\n",
      "323/323 [==============================] - 0s 281us/sample - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.4877 - val_accuracy: 0.8611\n",
      "Epoch 87/100\n",
      "323/323 [==============================] - 0s 300us/sample - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.4890 - val_accuracy: 0.8611\n",
      "Epoch 88/100\n",
      "323/323 [==============================] - 0s 318us/sample - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.4894 - val_accuracy: 0.8611\n",
      "Epoch 89/100\n",
      "323/323 [==============================] - 0s 250us/sample - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.4910 - val_accuracy: 0.8611\n",
      "Epoch 90/100\n",
      "323/323 [==============================] - 0s 284us/sample - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8611\n",
      "Epoch 91/100\n",
      "323/323 [==============================] - 0s 250us/sample - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.4932 - val_accuracy: 0.8611\n",
      "Epoch 92/100\n",
      "323/323 [==============================] - 0s 256us/sample - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.4953 - val_accuracy: 0.8611\n",
      "Epoch 93/100\n",
      "323/323 [==============================] - 0s 198us/sample - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.4963 - val_accuracy: 0.8611\n",
      "Epoch 94/100\n",
      "323/323 [==============================] - 0s 309us/sample - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.4953 - val_accuracy: 0.8611\n",
      "Epoch 95/100\n",
      "323/323 [==============================] - 0s 235us/sample - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.4995 - val_accuracy: 0.8611\n",
      "Epoch 96/100\n",
      "323/323 [==============================] - 0s 269us/sample - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.4987 - val_accuracy: 0.8333\n",
      "Epoch 97/100\n",
      "323/323 [==============================] - 0s 312us/sample - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.5023 - val_accuracy: 0.8333\n",
      "Epoch 98/100\n",
      "323/323 [==============================] - 0s 238us/sample - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.5038 - val_accuracy: 0.8333\n",
      "Epoch 99/100\n",
      "323/323 [==============================] - 0s 343us/sample - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.5035 - val_accuracy: 0.8611\n",
      "Epoch 100/100\n",
      "323/323 [==============================] - 0s 361us/sample - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.5046 - val_accuracy: 0.8611\n"
     ]
    }
   ],
   "source": [
    "#Activation function:LeakyReLU\n",
    "seed(0)\n",
    "tf.random.set_seed(0)   \n",
    "lr_res = keras.models.Sequential()\n",
    "lr_res.add(keras.layers.Dense(300,input_dim=X_res_train.shape[1],activation=keras.layers.LeakyReLU()))   \n",
    "lr_res.add(keras.layers.Dense(100, activation=keras.layers.LeakyReLU()))\n",
    "lr_res.add(keras.layers.Dense(2, activation=\"softmax\"))\n",
    "lr_res.compile(loss = \"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics = [\"accuracy\"])\n",
    "lr_res_history = lr_res.fit(x_n_res, y_n_res, epochs = 100, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 341us/sample - loss: 0.4050 - accuracy: 0.8537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4050306801388903, 0.85365856]"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_res.evaluate(X_res_test, Y_res_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323 samples, validate on 36 samples\n",
      "Epoch 1/100\n",
      "323/323 [==============================] - 1s 5ms/sample - loss: 5.3243 - accuracy: 0.4737 - val_loss: 5.3631 - val_accuracy: 0.4444\n",
      "Epoch 2/100\n",
      "323/323 [==============================] - 0s 195us/sample - loss: 5.2114 - accuracy: 0.5573 - val_loss: 5.2840 - val_accuracy: 0.4444\n",
      "Epoch 3/100\n",
      "323/323 [==============================] - 0s 309us/sample - loss: 5.1242 - accuracy: 0.6347 - val_loss: 5.1985 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "323/323 [==============================] - 0s 321us/sample - loss: 5.0559 - accuracy: 0.6966 - val_loss: 5.1721 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "323/323 [==============================] - 0s 287us/sample - loss: 4.9883 - accuracy: 0.7647 - val_loss: 5.1007 - val_accuracy: 0.6944\n",
      "Epoch 6/100\n",
      "323/323 [==============================] - 0s 198us/sample - loss: 4.9322 - accuracy: 0.7833 - val_loss: 5.0566 - val_accuracy: 0.7222\n",
      "Epoch 7/100\n",
      "323/323 [==============================] - 0s 188us/sample - loss: 4.8786 - accuracy: 0.8204 - val_loss: 5.0392 - val_accuracy: 0.6944\n",
      "Epoch 8/100\n",
      "323/323 [==============================] - 0s 318us/sample - loss: 4.8289 - accuracy: 0.8452 - val_loss: 4.9962 - val_accuracy: 0.6667\n",
      "Epoch 9/100\n",
      "323/323 [==============================] - 0s 389us/sample - loss: 4.7820 - accuracy: 0.8700 - val_loss: 4.9613 - val_accuracy: 0.7222\n",
      "Epoch 10/100\n",
      "323/323 [==============================] - 0s 330us/sample - loss: 4.7378 - accuracy: 0.8947 - val_loss: 4.9175 - val_accuracy: 0.7778\n",
      "Epoch 11/100\n",
      "323/323 [==============================] - 0s 318us/sample - loss: 4.6960 - accuracy: 0.9195 - val_loss: 4.8877 - val_accuracy: 0.7222\n",
      "Epoch 12/100\n",
      "323/323 [==============================] - 0s 303us/sample - loss: 4.6563 - accuracy: 0.9319 - val_loss: 4.8574 - val_accuracy: 0.8056\n",
      "Epoch 13/100\n",
      "323/323 [==============================] - 0s 219us/sample - loss: 4.6179 - accuracy: 0.9474 - val_loss: 4.8255 - val_accuracy: 0.7778\n",
      "Epoch 14/100\n",
      "323/323 [==============================] - 0s 398us/sample - loss: 4.5829 - accuracy: 0.9443 - val_loss: 4.8010 - val_accuracy: 0.7778\n",
      "Epoch 15/100\n",
      "323/323 [==============================] - ETA: 0s - loss: 4.5468 - accuracy: 0.97 - 0s 352us/sample - loss: 4.5478 - accuracy: 0.9567 - val_loss: 4.7787 - val_accuracy: 0.8056\n",
      "Epoch 16/100\n",
      "323/323 [==============================] - 0s 235us/sample - loss: 4.5135 - accuracy: 0.9659 - val_loss: 4.7451 - val_accuracy: 0.8333\n",
      "Epoch 17/100\n",
      "323/323 [==============================] - 0s 232us/sample - loss: 4.4807 - accuracy: 0.9659 - val_loss: 4.7219 - val_accuracy: 0.8056\n",
      "Epoch 18/100\n",
      "323/323 [==============================] - 0s 201us/sample - loss: 4.4496 - accuracy: 0.9721 - val_loss: 4.6957 - val_accuracy: 0.8056\n",
      "Epoch 19/100\n",
      "323/323 [==============================] - 0s 219us/sample - loss: 4.4191 - accuracy: 0.9783 - val_loss: 4.6803 - val_accuracy: 0.8056\n",
      "Epoch 20/100\n",
      "323/323 [==============================] - 0s 275us/sample - loss: 4.3899 - accuracy: 0.9752 - val_loss: 4.6519 - val_accuracy: 0.8056\n",
      "Epoch 21/100\n",
      "323/323 [==============================] - 0s 213us/sample - loss: 4.3599 - accuracy: 0.9845 - val_loss: 4.6260 - val_accuracy: 0.8056\n",
      "Epoch 22/100\n",
      "323/323 [==============================] - 0s 262us/sample - loss: 4.3317 - accuracy: 0.9907 - val_loss: 4.6106 - val_accuracy: 0.7778\n",
      "Epoch 23/100\n",
      "323/323 [==============================] - 0s 281us/sample - loss: 4.3053 - accuracy: 0.9907 - val_loss: 4.5873 - val_accuracy: 0.7778\n",
      "Epoch 24/100\n",
      "323/323 [==============================] - ETA: 0s - loss: 4.2783 - accuracy: 1.00 - 0s 247us/sample - loss: 4.2791 - accuracy: 0.9907 - val_loss: 4.5618 - val_accuracy: 0.8056\n",
      "Epoch 25/100\n",
      "323/323 [==============================] - 0s 225us/sample - loss: 4.2529 - accuracy: 0.9938 - val_loss: 4.5419 - val_accuracy: 0.8056\n",
      "Epoch 26/100\n",
      "323/323 [==============================] - 0s 195us/sample - loss: 4.2277 - accuracy: 0.9907 - val_loss: 4.5212 - val_accuracy: 0.8056\n",
      "Epoch 27/100\n",
      "323/323 [==============================] - 0s 188us/sample - loss: 4.2030 - accuracy: 0.9938 - val_loss: 4.5020 - val_accuracy: 0.8056\n",
      "Epoch 28/100\n",
      "323/323 [==============================] - 0s 191us/sample - loss: 4.1793 - accuracy: 0.9938 - val_loss: 4.4812 - val_accuracy: 0.8056\n",
      "Epoch 29/100\n",
      "323/323 [==============================] - 0s 213us/sample - loss: 4.1559 - accuracy: 0.9938 - val_loss: 4.4617 - val_accuracy: 0.8056\n",
      "Epoch 30/100\n",
      "323/323 [==============================] - 0s 201us/sample - loss: 4.1332 - accuracy: 0.9969 - val_loss: 4.4393 - val_accuracy: 0.8056\n",
      "Epoch 31/100\n",
      "323/323 [==============================] - 0s 179us/sample - loss: 4.1110 - accuracy: 0.9969 - val_loss: 4.4166 - val_accuracy: 0.8056\n",
      "Epoch 32/100\n",
      "323/323 [==============================] - 0s 185us/sample - loss: 4.0888 - accuracy: 0.9969 - val_loss: 4.4035 - val_accuracy: 0.8056\n",
      "Epoch 33/100\n",
      "323/323 [==============================] - 0s 244us/sample - loss: 4.0668 - accuracy: 1.0000 - val_loss: 4.3800 - val_accuracy: 0.8056\n",
      "Epoch 34/100\n",
      "323/323 [==============================] - 0s 395us/sample - loss: 4.0457 - accuracy: 0.9969 - val_loss: 4.3675 - val_accuracy: 0.8056\n",
      "Epoch 35/100\n",
      "323/323 [==============================] - 0s 219us/sample - loss: 4.0243 - accuracy: 1.0000 - val_loss: 4.3438 - val_accuracy: 0.8056\n",
      "Epoch 36/100\n",
      "323/323 [==============================] - 0s 266us/sample - loss: 4.0036 - accuracy: 1.0000 - val_loss: 4.3236 - val_accuracy: 0.8056\n",
      "Epoch 37/100\n",
      "323/323 [==============================] - 0s 281us/sample - loss: 3.9832 - accuracy: 1.0000 - val_loss: 4.3071 - val_accuracy: 0.8056\n",
      "Epoch 38/100\n",
      "323/323 [==============================] - 0s 253us/sample - loss: 3.9632 - accuracy: 1.0000 - val_loss: 4.2853 - val_accuracy: 0.8056\n",
      "Epoch 39/100\n",
      "323/323 [==============================] - 0s 182us/sample - loss: 3.9434 - accuracy: 1.0000 - val_loss: 4.2668 - val_accuracy: 0.8056\n",
      "Epoch 40/100\n",
      "323/323 [==============================] - 0s 173us/sample - loss: 3.9238 - accuracy: 1.0000 - val_loss: 4.2503 - val_accuracy: 0.8056\n",
      "Epoch 41/100\n",
      "323/323 [==============================] - 0s 176us/sample - loss: 3.9046 - accuracy: 1.0000 - val_loss: 4.2361 - val_accuracy: 0.8056\n",
      "Epoch 42/100\n",
      "323/323 [==============================] - 0s 198us/sample - loss: 3.8855 - accuracy: 1.0000 - val_loss: 4.2229 - val_accuracy: 0.8056\n",
      "Epoch 43/100\n",
      "323/323 [==============================] - 0s 219us/sample - loss: 3.8666 - accuracy: 1.0000 - val_loss: 4.2060 - val_accuracy: 0.8056\n",
      "Epoch 44/100\n",
      "323/323 [==============================] - 0s 349us/sample - loss: 3.8479 - accuracy: 1.0000 - val_loss: 4.1863 - val_accuracy: 0.8056\n",
      "Epoch 45/100\n",
      "323/323 [==============================] - 0s 324us/sample - loss: 3.8296 - accuracy: 1.0000 - val_loss: 4.1681 - val_accuracy: 0.7778\n",
      "Epoch 46/100\n",
      "323/323 [==============================] - 0s 204us/sample - loss: 3.8117 - accuracy: 1.0000 - val_loss: 4.1592 - val_accuracy: 0.8056\n",
      "Epoch 47/100\n",
      "323/323 [==============================] - 0s 204us/sample - loss: 3.7935 - accuracy: 1.0000 - val_loss: 4.1420 - val_accuracy: 0.8056\n",
      "Epoch 48/100\n",
      "323/323 [==============================] - 0s 185us/sample - loss: 3.7758 - accuracy: 1.0000 - val_loss: 4.1214 - val_accuracy: 0.8056\n",
      "Epoch 49/100\n",
      "323/323 [==============================] - 0s 176us/sample - loss: 3.7581 - accuracy: 1.0000 - val_loss: 4.1076 - val_accuracy: 0.8056\n",
      "Epoch 50/100\n",
      "323/323 [==============================] - 0s 266us/sample - loss: 3.7406 - accuracy: 1.0000 - val_loss: 4.0936 - val_accuracy: 0.8056\n",
      "Epoch 51/100\n",
      "323/323 [==============================] - 0s 185us/sample - loss: 3.7233 - accuracy: 1.0000 - val_loss: 4.0745 - val_accuracy: 0.8056\n",
      "Epoch 52/100\n",
      "323/323 [==============================] - 0s 204us/sample - loss: 3.7062 - accuracy: 1.0000 - val_loss: 4.0592 - val_accuracy: 0.8056\n",
      "Epoch 53/100\n",
      "323/323 [==============================] - 0s 191us/sample - loss: 3.6890 - accuracy: 1.0000 - val_loss: 4.0489 - val_accuracy: 0.8056\n",
      "Epoch 54/100\n",
      "323/323 [==============================] - 0s 207us/sample - loss: 3.6719 - accuracy: 1.0000 - val_loss: 4.0314 - val_accuracy: 0.8056\n",
      "Epoch 55/100\n",
      "323/323 [==============================] - 0s 164us/sample - loss: 3.6551 - accuracy: 1.0000 - val_loss: 4.0181 - val_accuracy: 0.8056\n",
      "Epoch 56/100\n",
      "323/323 [==============================] - 0s 364us/sample - loss: 3.6385 - accuracy: 1.0000 - val_loss: 3.9994 - val_accuracy: 0.8056\n",
      "Epoch 57/100\n",
      "323/323 [==============================] - 0s 210us/sample - loss: 3.6219 - accuracy: 1.0000 - val_loss: 3.9808 - val_accuracy: 0.8056\n",
      "Epoch 58/100\n",
      "323/323 [==============================] - 0s 164us/sample - loss: 3.6055 - accuracy: 1.0000 - val_loss: 3.9653 - val_accuracy: 0.8056\n",
      "Epoch 59/100\n",
      "323/323 [==============================] - 0s 182us/sample - loss: 3.5892 - accuracy: 1.0000 - val_loss: 3.9455 - val_accuracy: 0.8333\n",
      "Epoch 60/100\n",
      "323/323 [==============================] - 0s 164us/sample - loss: 3.5730 - accuracy: 1.0000 - val_loss: 3.9320 - val_accuracy: 0.8333\n",
      "Epoch 61/100\n",
      "323/323 [==============================] - 0s 161us/sample - loss: 3.5569 - accuracy: 1.0000 - val_loss: 3.9157 - val_accuracy: 0.8333\n",
      "Epoch 62/100\n",
      "323/323 [==============================] - 0s 170us/sample - loss: 3.5409 - accuracy: 1.0000 - val_loss: 3.9034 - val_accuracy: 0.8333\n",
      "Epoch 63/100\n",
      "323/323 [==============================] - 0s 167us/sample - loss: 3.5250 - accuracy: 1.0000 - val_loss: 3.8898 - val_accuracy: 0.8056\n",
      "Epoch 64/100\n",
      "323/323 [==============================] - 0s 213us/sample - loss: 3.5092 - accuracy: 1.0000 - val_loss: 3.8742 - val_accuracy: 0.8056\n",
      "Epoch 65/100\n",
      "323/323 [==============================] - 0s 210us/sample - loss: 3.4935 - accuracy: 1.0000 - val_loss: 3.8577 - val_accuracy: 0.8333\n",
      "Epoch 66/100\n",
      "323/323 [==============================] - 0s 161us/sample - loss: 3.4780 - accuracy: 1.0000 - val_loss: 3.8446 - val_accuracy: 0.8333\n",
      "Epoch 67/100\n",
      "323/323 [==============================] - 0s 164us/sample - loss: 3.4625 - accuracy: 1.0000 - val_loss: 3.8288 - val_accuracy: 0.8333\n",
      "Epoch 68/100\n",
      "323/323 [==============================] - 0s 191us/sample - loss: 3.4471 - accuracy: 1.0000 - val_loss: 3.8132 - val_accuracy: 0.8333\n",
      "Epoch 69/100\n",
      "323/323 [==============================] - 0s 167us/sample - loss: 3.4318 - accuracy: 1.0000 - val_loss: 3.7962 - val_accuracy: 0.8611\n",
      "Epoch 70/100\n",
      "323/323 [==============================] - 0s 164us/sample - loss: 3.4166 - accuracy: 1.0000 - val_loss: 3.7815 - val_accuracy: 0.8611\n",
      "Epoch 71/100\n",
      "323/323 [==============================] - 0s 170us/sample - loss: 3.4015 - accuracy: 1.0000 - val_loss: 3.7699 - val_accuracy: 0.8333\n",
      "Epoch 72/100\n",
      "323/323 [==============================] - 0s 164us/sample - loss: 3.3864 - accuracy: 1.0000 - val_loss: 3.7638 - val_accuracy: 0.8333\n",
      "Epoch 73/100\n",
      "323/323 [==============================] - 0s 167us/sample - loss: 3.3715 - accuracy: 1.0000 - val_loss: 3.7533 - val_accuracy: 0.8333\n",
      "Epoch 74/100\n",
      "323/323 [==============================] - 0s 170us/sample - loss: 3.3565 - accuracy: 1.0000 - val_loss: 3.7361 - val_accuracy: 0.8333\n",
      "Epoch 75/100\n",
      "323/323 [==============================] - 0s 170us/sample - loss: 3.3417 - accuracy: 1.0000 - val_loss: 3.7237 - val_accuracy: 0.8333\n",
      "Epoch 76/100\n",
      "323/323 [==============================] - 0s 173us/sample - loss: 3.3270 - accuracy: 1.0000 - val_loss: 3.7057 - val_accuracy: 0.8333\n",
      "Epoch 77/100\n",
      "323/323 [==============================] - 0s 173us/sample - loss: 3.3123 - accuracy: 1.0000 - val_loss: 3.6919 - val_accuracy: 0.8333\n",
      "Epoch 78/100\n",
      "323/323 [==============================] - 0s 176us/sample - loss: 3.2977 - accuracy: 1.0000 - val_loss: 3.6765 - val_accuracy: 0.8333\n",
      "Epoch 79/100\n",
      "323/323 [==============================] - 0s 161us/sample - loss: 3.2833 - accuracy: 1.0000 - val_loss: 3.6639 - val_accuracy: 0.8333\n",
      "Epoch 80/100\n",
      "323/323 [==============================] - 0s 185us/sample - loss: 3.2689 - accuracy: 1.0000 - val_loss: 3.6487 - val_accuracy: 0.8333\n",
      "Epoch 81/100\n",
      "323/323 [==============================] - 0s 191us/sample - loss: 3.2546 - accuracy: 1.0000 - val_loss: 3.6349 - val_accuracy: 0.8333\n",
      "Epoch 82/100\n",
      "323/323 [==============================] - 0s 525us/sample - loss: 3.2403 - accuracy: 1.0000 - val_loss: 3.6205 - val_accuracy: 0.8611\n",
      "Epoch 83/100\n",
      "323/323 [==============================] - 0s 364us/sample - loss: 3.2261 - accuracy: 1.0000 - val_loss: 3.6071 - val_accuracy: 0.8611\n",
      "Epoch 84/100\n",
      "323/323 [==============================] - 0s 213us/sample - loss: 3.2120 - accuracy: 1.0000 - val_loss: 3.5927 - val_accuracy: 0.8611\n",
      "Epoch 85/100\n",
      "323/323 [==============================] - 0s 198us/sample - loss: 3.1979 - accuracy: 1.0000 - val_loss: 3.5820 - val_accuracy: 0.8333\n",
      "Epoch 86/100\n",
      "323/323 [==============================] - 0s 256us/sample - loss: 3.1839 - accuracy: 1.0000 - val_loss: 3.5657 - val_accuracy: 0.8611\n",
      "Epoch 87/100\n",
      "323/323 [==============================] - 0s 216us/sample - loss: 3.1700 - accuracy: 1.0000 - val_loss: 3.5533 - val_accuracy: 0.8611\n",
      "Epoch 88/100\n",
      "323/323 [==============================] - 0s 198us/sample - loss: 3.1562 - accuracy: 1.0000 - val_loss: 3.5394 - val_accuracy: 0.8611\n",
      "Epoch 89/100\n",
      "323/323 [==============================] - 0s 191us/sample - loss: 3.1424 - accuracy: 1.0000 - val_loss: 3.5260 - val_accuracy: 0.8611\n",
      "Epoch 90/100\n",
      "323/323 [==============================] - 0s 216us/sample - loss: 3.1287 - accuracy: 1.0000 - val_loss: 3.5125 - val_accuracy: 0.8611\n",
      "Epoch 91/100\n",
      "323/323 [==============================] - 0s 281us/sample - loss: 3.1151 - accuracy: 1.0000 - val_loss: 3.4990 - val_accuracy: 0.8611\n",
      "Epoch 92/100\n",
      "323/323 [==============================] - 0s 232us/sample - loss: 3.1015 - accuracy: 1.0000 - val_loss: 3.4890 - val_accuracy: 0.8611\n",
      "Epoch 93/100\n",
      "323/323 [==============================] - 0s 290us/sample - loss: 3.0879 - accuracy: 1.0000 - val_loss: 3.4750 - val_accuracy: 0.8611\n",
      "Epoch 94/100\n",
      "323/323 [==============================] - 0s 309us/sample - loss: 3.0745 - accuracy: 1.0000 - val_loss: 3.4578 - val_accuracy: 0.8611\n",
      "Epoch 95/100\n",
      "323/323 [==============================] - 0s 312us/sample - loss: 3.0611 - accuracy: 1.0000 - val_loss: 3.4508 - val_accuracy: 0.8611\n",
      "Epoch 96/100\n",
      "323/323 [==============================] - 0s 272us/sample - loss: 3.0478 - accuracy: 1.0000 - val_loss: 3.4357 - val_accuracy: 0.8611\n",
      "Epoch 97/100\n",
      "323/323 [==============================] - 0s 303us/sample - loss: 3.0345 - accuracy: 1.0000 - val_loss: 3.4282 - val_accuracy: 0.8333\n",
      "Epoch 98/100\n",
      "323/323 [==============================] - 0s 232us/sample - loss: 3.0212 - accuracy: 1.0000 - val_loss: 3.4159 - val_accuracy: 0.8333\n",
      "Epoch 99/100\n",
      "323/323 [==============================] - 0s 213us/sample - loss: 3.0081 - accuracy: 1.0000 - val_loss: 3.3998 - val_accuracy: 0.8611\n",
      "Epoch 100/100\n",
      "323/323 [==============================] - 0s 250us/sample - loss: 2.9950 - accuracy: 1.0000 - val_loss: 3.3858 - val_accuracy: 0.8611\n"
     ]
    }
   ],
   "source": [
    "#With L2 Regularisation\n",
    "seed(0)\n",
    "tf.random.set_seed(0)   \n",
    "L2_res = keras.models.Sequential()\n",
    "L2_res.add(keras.layers.Dense(300, activation=\"relu\",input_dim=X_res_train.shape[1],kernel_regularizer=keras.regularizers.l2(0.01)))   \n",
    "L2_res.add(keras.layers.Dense(100, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "L2_res.add(keras.layers.Dense(2, activation=\"softmax\"))\n",
    "L2_res.compile(loss = \"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics = [\"accuracy\"])\n",
    "L2_res_history = L2_res.fit(x_n_res, y_n_res, epochs = 100, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 1ms/sample - loss: 0.4050 - accuracy: 0.8537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4050306801388903, 0.85365856]"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_res.evaluate(X_res_test, Y_res_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323 samples, validate on 36 samples\n",
      "Epoch 1/100\n",
      "323/323 [==============================] - 2s 6ms/sample - loss: 0.8522 - accuracy: 0.4644 - val_loss: 0.8775 - val_accuracy: 0.4167\n",
      "Epoch 2/100\n",
      "323/323 [==============================] - 0s 207us/sample - loss: 0.7938 - accuracy: 0.5201 - val_loss: 0.7906 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "323/323 [==============================] - 0s 216us/sample - loss: 0.7232 - accuracy: 0.5882 - val_loss: 0.7220 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "323/323 [==============================] - 0s 287us/sample - loss: 0.6704 - accuracy: 0.6130 - val_loss: 0.7030 - val_accuracy: 0.5833\n",
      "Epoch 5/100\n",
      "323/323 [==============================] - 0s 414us/sample - loss: 0.6353 - accuracy: 0.6378 - val_loss: 0.6639 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "323/323 [==============================] - 0s 423us/sample - loss: 0.5931 - accuracy: 0.6749 - val_loss: 0.6388 - val_accuracy: 0.7500\n",
      "Epoch 7/100\n",
      "323/323 [==============================] - 0s 232us/sample - loss: 0.5378 - accuracy: 0.7090 - val_loss: 0.6489 - val_accuracy: 0.6111\n",
      "Epoch 8/100\n",
      "323/323 [==============================] - 0s 256us/sample - loss: 0.5150 - accuracy: 0.7337 - val_loss: 0.6216 - val_accuracy: 0.6667\n",
      "Epoch 9/100\n",
      "323/323 [==============================] - 0s 241us/sample - loss: 0.5052 - accuracy: 0.7337 - val_loss: 0.6053 - val_accuracy: 0.6944\n",
      "Epoch 10/100\n",
      "323/323 [==============================] - 0s 250us/sample - loss: 0.4879 - accuracy: 0.7771 - val_loss: 0.5826 - val_accuracy: 0.7778\n",
      "Epoch 11/100\n",
      "323/323 [==============================] - 0s 232us/sample - loss: 0.4509 - accuracy: 0.8050 - val_loss: 0.5825 - val_accuracy: 0.7222\n",
      "Epoch 12/100\n",
      "323/323 [==============================] - 0s 232us/sample - loss: 0.4237 - accuracy: 0.8297 - val_loss: 0.5580 - val_accuracy: 0.7778\n",
      "Epoch 13/100\n",
      "323/323 [==============================] - 0s 284us/sample - loss: 0.4218 - accuracy: 0.8204 - val_loss: 0.5469 - val_accuracy: 0.8056\n",
      "Epoch 14/100\n",
      "323/323 [==============================] - 0s 275us/sample - loss: 0.4067 - accuracy: 0.8297 - val_loss: 0.5388 - val_accuracy: 0.8056\n",
      "Epoch 15/100\n",
      "323/323 [==============================] - 0s 228us/sample - loss: 0.3763 - accuracy: 0.8421 - val_loss: 0.5392 - val_accuracy: 0.7778\n",
      "Epoch 16/100\n",
      "323/323 [==============================] - 0s 225us/sample - loss: 0.3667 - accuracy: 0.8669 - val_loss: 0.5158 - val_accuracy: 0.8056\n",
      "Epoch 17/100\n",
      "323/323 [==============================] - 0s 278us/sample - loss: 0.3445 - accuracy: 0.8700 - val_loss: 0.5092 - val_accuracy: 0.8056\n",
      "Epoch 18/100\n",
      "323/323 [==============================] - 0s 216us/sample - loss: 0.3350 - accuracy: 0.8824 - val_loss: 0.4994 - val_accuracy: 0.8056\n",
      "Epoch 19/100\n",
      "323/323 [==============================] - 0s 185us/sample - loss: 0.3123 - accuracy: 0.9102 - val_loss: 0.4928 - val_accuracy: 0.8056\n",
      "Epoch 20/100\n",
      "323/323 [==============================] - 0s 201us/sample - loss: 0.3037 - accuracy: 0.8978 - val_loss: 0.4849 - val_accuracy: 0.7778\n",
      "Epoch 21/100\n",
      "323/323 [==============================] - 0s 232us/sample - loss: 0.2740 - accuracy: 0.9133 - val_loss: 0.4704 - val_accuracy: 0.7778\n",
      "Epoch 22/100\n",
      "323/323 [==============================] - 0s 213us/sample - loss: 0.2743 - accuracy: 0.8978 - val_loss: 0.4712 - val_accuracy: 0.8056\n",
      "Epoch 23/100\n",
      "323/323 [==============================] - 0s 238us/sample - loss: 0.2540 - accuracy: 0.9257 - val_loss: 0.4681 - val_accuracy: 0.8056\n",
      "Epoch 24/100\n",
      "323/323 [==============================] - 0s 278us/sample - loss: 0.2463 - accuracy: 0.9226 - val_loss: 0.4626 - val_accuracy: 0.7778\n",
      "Epoch 25/100\n",
      "323/323 [==============================] - 0s 333us/sample - loss: 0.2439 - accuracy: 0.9164 - val_loss: 0.4654 - val_accuracy: 0.8056\n",
      "Epoch 26/100\n",
      "323/323 [==============================] - 0s 312us/sample - loss: 0.2219 - accuracy: 0.9195 - val_loss: 0.4517 - val_accuracy: 0.8056\n",
      "Epoch 27/100\n",
      "323/323 [==============================] - 0s 188us/sample - loss: 0.2045 - accuracy: 0.9505 - val_loss: 0.4449 - val_accuracy: 0.7778\n",
      "Epoch 28/100\n",
      "323/323 [==============================] - 0s 188us/sample - loss: 0.2103 - accuracy: 0.9412 - val_loss: 0.4419 - val_accuracy: 0.7778\n",
      "Epoch 29/100\n",
      "323/323 [==============================] - 0s 185us/sample - loss: 0.2024 - accuracy: 0.9350 - val_loss: 0.4384 - val_accuracy: 0.7778\n",
      "Epoch 30/100\n",
      "323/323 [==============================] - 0s 216us/sample - loss: 0.2049 - accuracy: 0.9226 - val_loss: 0.4628 - val_accuracy: 0.8056\n",
      "Epoch 31/100\n",
      "323/323 [==============================] - 0s 188us/sample - loss: 0.1828 - accuracy: 0.9474 - val_loss: 0.4401 - val_accuracy: 0.7778\n",
      "Epoch 32/100\n",
      "323/323 [==============================] - 0s 244us/sample - loss: 0.1765 - accuracy: 0.9628 - val_loss: 0.4464 - val_accuracy: 0.8056\n",
      "Epoch 33/100\n",
      "323/323 [==============================] - 0s 213us/sample - loss: 0.1510 - accuracy: 0.9659 - val_loss: 0.4298 - val_accuracy: 0.7778\n",
      "Epoch 34/100\n",
      "323/323 [==============================] - 0s 216us/sample - loss: 0.1574 - accuracy: 0.9659 - val_loss: 0.4432 - val_accuracy: 0.8056\n",
      "Epoch 35/100\n",
      "323/323 [==============================] - 0s 188us/sample - loss: 0.1688 - accuracy: 0.9474 - val_loss: 0.4319 - val_accuracy: 0.7778\n",
      "Epoch 36/100\n",
      "323/323 [==============================] - 0s 216us/sample - loss: 0.1442 - accuracy: 0.9690 - val_loss: 0.4187 - val_accuracy: 0.8056\n",
      "Epoch 37/100\n",
      "323/323 [==============================] - 0s 195us/sample - loss: 0.1478 - accuracy: 0.9659 - val_loss: 0.4208 - val_accuracy: 0.8056\n",
      "Epoch 38/100\n",
      "323/323 [==============================] - 0s 185us/sample - loss: 0.1296 - accuracy: 0.9783 - val_loss: 0.4181 - val_accuracy: 0.8056\n",
      "Epoch 39/100\n",
      "323/323 [==============================] - 0s 191us/sample - loss: 0.1154 - accuracy: 0.9876 - val_loss: 0.4161 - val_accuracy: 0.8056\n",
      "Epoch 40/100\n",
      "323/323 [==============================] - 0s 266us/sample - loss: 0.1175 - accuracy: 0.9783 - val_loss: 0.4190 - val_accuracy: 0.8056\n",
      "Epoch 41/100\n",
      "323/323 [==============================] - 0s 179us/sample - loss: 0.1178 - accuracy: 0.9845 - val_loss: 0.4634 - val_accuracy: 0.8056\n",
      "Epoch 42/100\n",
      "323/323 [==============================] - 0s 182us/sample - loss: 0.1330 - accuracy: 0.9628 - val_loss: 0.4448 - val_accuracy: 0.8056\n",
      "Epoch 43/100\n",
      "323/323 [==============================] - 0s 364us/sample - loss: 0.1010 - accuracy: 0.9845 - val_loss: 0.4345 - val_accuracy: 0.7778\n",
      "Epoch 44/100\n",
      "323/323 [==============================] - 0s 259us/sample - loss: 0.0966 - accuracy: 0.9845 - val_loss: 0.4333 - val_accuracy: 0.7778\n",
      "Epoch 45/100\n",
      "323/323 [==============================] - 0s 229us/sample - loss: 0.1153 - accuracy: 0.9876 - val_loss: 0.4330 - val_accuracy: 0.8056\n",
      "Epoch 46/100\n",
      "323/323 [==============================] - 0s 228us/sample - loss: 0.1063 - accuracy: 0.9783 - val_loss: 0.4461 - val_accuracy: 0.7778\n",
      "Epoch 47/100\n",
      "323/323 [==============================] - 0s 201us/sample - loss: 0.0960 - accuracy: 0.9752 - val_loss: 0.4416 - val_accuracy: 0.7778\n",
      "Epoch 48/100\n",
      "323/323 [==============================] - 0s 198us/sample - loss: 0.0907 - accuracy: 0.9814 - val_loss: 0.4410 - val_accuracy: 0.7778\n",
      "Epoch 49/100\n",
      "323/323 [==============================] - 0s 225us/sample - loss: 0.0894 - accuracy: 0.9845 - val_loss: 0.4345 - val_accuracy: 0.7778\n"
     ]
    }
   ],
   "source": [
    "#Drop Out\n",
    "seed(0)\n",
    "tf.random.set_seed(0)  \n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "drop_res = keras.models.Sequential()\n",
    "drop_res.add(keras.layers.Dense(300,input_dim=X_res_train.shape[1],activation=\"relu\"))   \n",
    "drop_res.add(keras.layers.Dropout(rate=0.2))\n",
    "drop_res.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "drop_res.add(keras.layers.Dropout(rate=0.2))\n",
    "drop_res.add(keras.layers.Dense(2, activation=\"softmax\"))\n",
    "drop_res.compile(loss = \"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics = [\"accuracy\"])\n",
    "drop_res_history = drop_res.fit(x_n_res, y_n_res, epochs = 100, validation_split=0.1, callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 316us/sample - loss: 0.4028 - accuracy: 0.7805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4027860179180052, 0.7804878]"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_res.evaluate(X_res_test, Y_res_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZwU1b3//9enl+meHZgZYGbYkVWEAQZlU8HERI0ajUbjjVv0XvwmN9Ebv7km5pffT3N/5v4S5ctNTLzXh8YlRlwSXJOgMSKKCoqDILsiMMCwzb4vvdT5/XFqFnAGR5ienun5PB+PsrurqqtOdeO7z5w6dUqMMSillEo8nngXQCmlVGxowCulVILSgFdKqQSlAa+UUglKA14ppRKUBrxSSiUoDXillEpQGvBqQBKRYhH5crzLoVQsacArpVSC0oBXqgMR+RcR+VREKkXkZRHJc+eLiPyXiJSKSI2IbBaRae6yi0Rku4jUichBEflRfI9CKUsDXimXiJwH/H/AVUAusA94xl38FeAcYCIwCLgaqHCXPQLcYoxJB6YBb/RisZXqki/eBVCqD/k28Kgx5kMAEbkTqBKRMUAYSAcmA+uNMTs6vC8MTBWRj4wxVUBVr5ZaqS5oDV6pdnnYWjsAxph6bC093xjzBvA74AHgqIg8JCIZ7qpXABcB+0TkLRGZ18vlVqpTGvBKtTsEjG59ISKpQBZwEMAYc78xZjZwOrap5t/d+R8YY74ODAVeBP7Uy+VWqlMa8Gog84tIsHXCBvN3RKRARALAfwLvG2OKRWSOiJwlIn6gAWgGoiKSJCLfFpFMY0wYqAWicTsipTrQgFcD2UqgqcN0NvB/A88Bh4HxwLfcdTOAh7Ht6/uwTTdL3WXXAcUiUgv8L+DaXiq/UickesMPpZRKTFqDV0qpBKUBr5RSCUoDXimlEpQGvFJKJag+dSVrdna2GTNmTLyLoZRS/caGDRvKjTE5nS3rUwE/ZswYioqK4l0MpZTqN0RkX1fLtIlGKaUSlAa8UkolKA14pZRKUH2qDb4z4XCYkpISmpub412UASMYDDJixAj8fn+8i6KUOgV9PuBLSkpIT09nzJgxiEi8i5PwjDFUVFRQUlLC2LFj410cpdQp6PNNNM3NzWRlZWm49xIRISsrS/9iUioB9PmABzTce5l+3kolhn4R8CdkDNQdgVBDvEuilFJ9SgIEfBQayqGqGJzY3GfB6/VSUFDAtGnTuOSSS6iurv7c96SlpX1m3o033siKFSs+dz2llOoJ/T/gPT4YPAaiIag5YGv0PSw5OZlNmzaxdetWhgwZwgMPPNDj+1BKqZ7W/wMeIJAG6bnQVAVNlTHd1bx58zh48GDb6/vuu485c+Ywffp07rrrrpjuWymlvog+302yo5//ZRvbD9V2vUK4CUw5+FNAuvfbNTUvg7suOb1b60ajUVatWsXNN98MwGuvvcauXbtYv349xhguvfRS1qxZwznnnNOt7SmlVCwlRg2+lT8ICESagJ5rqmlqaqKgoICsrCwqKys5//zzARvwr732GjNnzmTWrFns3LmTXbt2dbmdznqnaI8VpVSs9KsafLdq2qEGqPgUvEmQNQG8p36IrW3wNTU1XHzxxTzwwAPceuutGGO48847ueWWW7q1naysLKqqqtpeV1ZWkp2dfcrlU0qpziRWDR4gKRWGjINIC1Tu7tGeNZmZmdx///0sXbqUcDjMV7/6VR599FHq6+sBOHjwIKWlpV2+f9GiRTz77LOEQiEAHn/8cRYvXtxj5VNKqY76VQ2+2wLpMGQsVO61tfkhY22NvgfMnDmTGTNm8Mwzz3DdddexY8cO5s2bB9guj08++SRDhw6lsbGRESNGtL3v9ttv5/bbb2fDhg3Mnj0br9fL+PHjefDBB3ukXEopdTwxMehWeLIKCwvN8Tf82LFjB1OmTDm5DTbX2P7x4rUhn5R66oUcIE7pc1dK9RoR2WCMKexsWUybaESkWES2iMgmEen9WzUFMyF7IohA+S5ojG0XSqWU6kt6o4lmsTGmvBf20zl/sg35qr1QvQ8izbbPvPZeUUoluMQ7ydoZrx+yToOULKg/CpV7YjasgVJK9RWxDngDvCYiG0RkSWcriMgSESkSkaKysrLYlUQ8kDkSMkdASy2UfawDlCmlElqsA36BMWYWcCHwryLymUs8jTEPGWMKjTGFOTk5sS2NCKTm2No8Bso/gdpDYJzY7lcppeIgpgFvjDnkPpYCLwBnxnJ/3RZIh5zJ7U02WptXSiWgmAW8iKSKSHrrc+ArwNZY7e8L83hh0Ch7UZQTtbX5moOdts13NqTvsmXLmDp1KtOnT+dLX/oS+/bt641SK6VUt8WyBj8MeEdEPgLWA38zxrwaw/2dnGAmDHVr8w2lULbT9p//HDNnzqSoqIjNmzdz5ZVXcscdd/RCYZVSqvti1k3SGLMHmBGr7fcoj8/W5pMH2zHlK/dAIBMy88EX6PQtHYcYmDt3Lk8++WRvlVYppbqlfw1V8MpP4MiWnt3m8DPgwl/a561t8/VlUH8ESndA2tDP3cQjjzzChRde2LPlUkqpU9S/Ar43iAfSh9nafN0hexLWONBYAclDPnOB1JNPPklRURFvvfVWnAqslFKd618B31rT7g2+JHsrwNQcQKB6P9SXQkYeBDJAhNdff51f/OIXvPXWWwQCnTflKKVUvPSvgI+HpFRbax88BmoP2/Z5fyob95Ryyy238OqrrzJ06Oc34yilVG/TgO+GxsZGRkw4w74wDrf/y7dZuWoN9XU1fPPKK0A8jBo1ipdffjm+BVVKqQ404LvBcZzjZ3D7j8pt+7wTgaQ0SBsGxuggZkqpPkMD/mR4PLZ3TUo2NJbbtvnK3fZm32nDbN96DXqlVJxpwJ+K1qBPzbZjzdcftcMSewN2fvIQu45SSsWBBnxPEI8N+ZQsaK6GuqP2gqm6w3ZeSrbtlaOUUr1IA74nidj+88FBEKqHhjJbq68/apttUnNse7023yileoEGfCyI2KtiA+kQabHt9A0VdowbX9DW9pOH2AHPlFIqRjTgY80XgIx8SMuFpipbq68psePQpwyxzTf+5HiXUimVgPQMYDd0NlzwF/X4E0/w/R/fBTmT7D1ig5m2Vl+2E8o+sUMhdHEbwbvvvpv8/HwKCgqYOnUqTz/99Ofu7+6772bp0qXHzCsuLmbatGmfu55SKjFowPc2EXt17OAxMOx0O/SBE7FDIRzdZh9DDbZPfQc//OEP2bRpEy+99BK33HIL4XA4PuVXSvUbGvAnqaysjCuuuII5c+YwZ84c3n33XQDWr1/P/PnzmTlzJvPnz+fjjz/+zHv/9re/MW/ePA4cOsLYM+YSHnwaZJ1GbcjDmDPmEj68zY5kWXcEIqFj3jthwgRSUlKoqqoCYPfu3VxwwQXMnj2bs88+m507d8b+4JVS/UK/aoP/1fpfsbOyZwNs8pDJ/PjMH3/h991222388Ic/ZOHChezfv5+vfvWr7Nixg8mTJ7NmzRp8Ph+vv/46P/3pT3nuuefa3vfCCy+wbNkyVq5cyeDBg1m0aBF/W7mSyy67jGf+vpYrvnk1/uxxtr2+7rCdGisgScCJ8OGmzUyYMKFt/JslS5bw4IMPMmHCBN5//32+973v8cYbb/TY56OU6r/6VcD3Ja+//jrbt29ve11bW0tdXR01NTXccMMN7Nq1CxE5pill9erVFBUV8dprr5GRkQHAP//zP3Pvvfdy2WWX8dhjj/Hwww/bXjap2bYHTlMlOA7/9dsHePiRx9iz/yCvvrQCjEN9QyNr167lm9/8Zts+WlpauiyzdNE9s6v5Sqn+rV8F/MnUtGPFcRzWrVtHcvKxPWB+8IMfsHjxYl544QWKi4tZtGhR27Jx48axZ88ePvnkEwoLCwFYsGABxcXFvPXWW0Sj0WNPgvoCkJ4Lqdn88LZ/40ffvZ7nV/yZ62/+F3av/RuON4VBgzLZtHFjt/rWZ2VltTXttKqsrGTs2LEn/0EopfosbYM/SV/5ylf43e9+1/Z606ZNANTU1JCfnw/A448/fsx7Ro8ezfPPP8/111/Ptm3b2uZff/31XHPNNXznO9/pfGci9krYzBF846Z/o7BwDn948R9k+COMzR/Gn3+/DGpKMM21fOSWozNpaWnk5uayatUqwIb7q6++ysKFC0/mI1BK9XEa8N3Q2NjIiBEj2qZly5Zx//33U1RUxPTp05k6dSoPPvggAHfccQd33nknCxYsIBr9bLfHSZMmsXz5cr75zW+ye/duAL797W9TVVXFNddc8/mFEeH/ufs/WPbgH3ByprL8j3/gkWdeYsa88zh9egEvPfWw7YkTaeaee+45ptwATzzxBPfccw8FBQWcd9553HXXXYwfP77nPiylVJ8h5rjuePFUWFhoioqKjpm3Y8cOpkyZEqcS9Y4VK1bw0ksv8cc//vHkN+JEoaUWmmrso4naMXICGZA8yD5+gStnB8LnrlQiEJENxpjCzpb1qzb4RPSDH/yAV155hZUrV57ahjxeOw5O8mB7D9mWejvwWXONfcQdPiGYaSevv0fKr5TquzTg4+y3v/1tz29UPBDMsJMx9sKp1rCvqbUjXfpTbNAHMuxQCdqTRqmEowGf6EQgkGanjHyINLu1+pr2fvYev/0xCGTYWr4OgqZUQtCAH0hEbG3dnwzpwyEatu31zTX2wqrGCsAdSqGlFo5uh6FTtHavVD+lAT+Qef3uDUmybLt9qAGaa92TtdXwP1+B9DwYfx6MXwzjFkNqVrxLrZTqJg14ZYmnfQx78qEsApf8Bna/ATv/ApuetOsNn94e9qPmgT8Y12IrpbqmAf8F3X333aSlpfGjH/0o3kXh17/+NUuWLCElJaXnN+7xwewb7eRE4dBG2L0a9qyGdf8N7/7G3rxk1DwYt8iG/rAz9B60SvUhMQ94EfECRcBBY8zFsd5fvEQiEXy+3v29/PWvf821114bm4DvyOOFEYV2OvffbRfMfWtt2O9eDa/fZaeULBh7jp3GnANZ47X9Xqk46o1Eug3YAWT0wr5i4he/+AVPPPEEI0eOJCcnh9mzZwOwaNEi5s+fz7vvvsull17KlVdeyU033URZWRk5OTk89thjjBo1ihtvvJFgMMi2bds4evQoy5Yt4+KLj/2tM8Zwxx138MorryAi/OxnP+Pqq6/mzTffZOnSpfz1r38F4Pvf/z6FhYXU1tZy6NAhFi9eTHZ2NqtXr+69DySQBhO/YiewwxrvecsG/p63YNsLdn56Xnvgjz0HBo3svTIqpWIb8CIyAvga8Avg9lPd3pH//E9advTscMGBKZMZ/tOfdrl8w4YNPPPMM2zcuJFIJMKsWbPaAh6gurqat956C4BLLrmE66+/nhtuuIFHH32UW2+9lRdffBGgbUCx3bt3s3jxYj799FOCwfb26+eff55Nmzbx0UcfUV5ezpw5czjnnHO6LNett97KsmXLWL16NdnZ2af6MZya9OEw42o7GQOVe2DvGjt9+jpsfsauN2g0jDkbxiyEMQtg0Kj4llupBBfrGvyvgTuA9BjvJ2befvttLr/88rZmkEsvvfSY5VdffXXb83Xr1vH8888DcN1113HHHXe0LbvqqqvweDxMmDCBcePGsXPnTgoKCtqWv/POO1xzzTV4vV6GDRvGueeeywcffNA2rHC/IWKbZrLGQ+F3bOCX7oC9b0HxO/Dx39pP2A4aBaMXwuj5dhoyTpt0lOpBMQt4EbkYKDXGbBCRRSdYbwmwBGDUqBPX6E5U046lE42Xnpqa2q33Hb+N4193NSaQz+fDcZy2183NzScsa58jAsOm2mnud8FxoHQ77HsXit+GXX+Hj56y66bn2pO2o+fbx6FT9aStUqcglv/3LAAuFZFi4BngPBF58viVjDEPGWMKjTGFOTk5MSzOyTnnnHN44YUXaGpqoq6ujr/85S9drjt//nyeecY2RyxfvvyYYXj//Oc/4zgOu3fvZs+ePUyaNOkz+3n22WeJRqOUlZWxZs0azjzzTEaPHs327dtpaWmhpqambahfgPT0dOrq6nr4iGPM44Hh0+CsW+DqJ+Hfd8O/roeL/wtGL4D978HKH8GDC+DeMbD8Knh7GexbB+F+9uOmVJzFrAZvjLkTuBPArcH/yBhzbaz2FyuzZs3i6quvpqCggNGjR3P22Wd3ue7999/PTTfdxH333dd2krXVpEmTOPfcczl69CgPPvjgMe3vAJdffjnr1q1jxowZiAj33nsvw4cPB2zzzvTp05kwYQIzZ85se8+SJUu48MILyc3N7d2TrD1JBHIm2anwJtukU73PBvp+d9r1d7uuNwnyZsLIs2wNf+RZeuGVUifQK8MFdwj4E3aTTNThgm+88UYuvvhirrzyyngXpdv61OfeUA4H3re1+/3v2T75jnsrxKwJbuCfBSPnQtZp2qyjBpS4DxdsjHkTeLM39qUSUGo2TP6ancA21RzaaGv3B9bDxyvbT9wmD4YRc2DkmfYxf7Z7da5SA49eydoLjr91nzpF/iCMnmcnsM065bugZL1b038fdr1ml4nHnqzNn20Df8QcyJ6otXw1IGjAq/5PBHIm2mmme5qnqQoOboADH0DJB7D9RfjwD3ZZIKND4BdCfqG25auEpAGvElPyYDjty3YC2z2z4lM4WGQDv+QDeHupHUUTYPAYG/T5s23oD5+uA6mpfk8DXg0MHk97Lb/gn+y8UAMc2uSGfpFt09+6wl3fB8NOt4HfOmVP1JuhqH5FA14NXEmpdsiEMQva59UetoF/8EPbxLNlBRQ96q6fBrkzbFfN/FmQN8vW/PXqW9VHacB/jurqap566im+973vndT7Fy1axNKlSyks7LQXk+prMnIh4xKYcol93da0swEOfWiDf/1DEA3Z5clDjg38/Fl2bB6l+gAN+M9RXV3Nf//3f590wKt+7pimnWvsvEgISrfZsD/0IRzcCG//n/b2/Ix8G/p5BZDrPqbGeUA4NSBpwH+On/zkJ+zevZuCggIWL17M5s2bqaqqIhwOc8899/D1r3+d4uJiLrzwQhYuXMjatWvJz8/npZdeIjk5GbDDFHzve9+jurqaRx555IRXw6p+wOdeUZs3E7jZzgs1wJEt7aF/aCPs/Gv7ezJHQZ7bvJNbYB9ThsSl+Grg6FcB//afPqH8QH2PbjN7ZBpnXzWxy+W//OUv2bp1K5s2bSISidDY2EhGRgbl5eXMnTu3bXTJXbt28fTTT/Pwww9z1VVX8dxzz3HttbbLXiQSYf369axcuZKf//znvP766z16DKoPSEqFUXPt1KqpGo5stidyD22Ew5tgR4exjFpDP3eG1vRVTPSrgI83Yww//elPWbNmDR6Ph4MHD3L06FEAxo4d2zb87+zZsykuLm573ze+8Y1O56sElzyo/WYnrZqq4PBHdjq06bOhn5HvBn6HKT1XT+Sqk9KvAv5ENe3esHz5csrKytiwYQN+v58xY8a0Dd8bCATa1vN6vTQ1NbW9bl3m9XqJRCK9W2jVtyQPtvewHbeofV5zjW3eObSpPfw/fgVwx4lKHQq5023YD59unw8eq6GvPle/Cvh46Dgkb01NDUOHDsXv97N69Wr27dsX59KphBDMdO9y1T68NC31NvSPbG4P/T1vguNWEAKZMPwMG/bDp9vnOZPA64/LIai+SQP+c2RlZbFgwQKmTZvGnDlz2LlzJ4WFhRQUFDB58uR4F08lqkDasePtgB1krXS7G/qb7WPRYxBx/1r0BmDolA6hP91erBVIi88xqLjrleGCuytRhwvuj/Rz7yecqB1orbWm31rrb6pyV3BvoTj8DHdya/tpw7SJJ0HEfbhgpVSMeLwwdLKdpl9l5xkDNSVwdKsN/MMf2V48215of19Kthv409ya/jTInqBNPAlGA16pRCMCg0baadKF7fOba+DIVjf4N9vwf/8hiLbY5d4kyJlsg3/YNBv+w6Zpf/1+rF8EvDHmhDe+Vj2rLzXbqR4UzPzs2DvRCFTscpt2ttjw3/UabFrevk5Gvg36Yae3h/6Q8eDtF/ExoPX5bygYDFJRUUFWVpaGfC8wxlBRUfGZe8aqBOX12ROzQ6e0N/EA1Je2B35rrX/3qvZePL6gre0fH/xa2+9T+vxJ1nA4TElJSVt/cxV7wWCQESNG4Pdre6zqINIC5Z+0B/7RrXB0OzSUtq+TnmvvoDXsdDf8p9phln2BrrerTkm/Psnq9/sZO3ZsvIuhlPIF2nvjdFRf6ob9Njsd2QrFb7ePuOnx2ZujD5vaHv5Dp8KgUdqTJ8b6fMArpfq4tKGQdh6MP699XjQMFbtt8Jdut8F/4APY+lz7Oknptmlo2FQYerr7/HRt5ulBGvBKqZ7n9bd33+youQZKd9jAL91um3i2vQAbHm9fJ214e9i3nh/ImWwHdFNfiAa8Uqr3BDM/O+qmMVB3uD3wS3fY5x/8HiKt597E3j1r6NT20B86xTb9+JLicST9gga8Uiq+RCAjz06tN0kHe5VuVXF78JftsOH/yatgou57vZB12rGhnzMFhozTbpxowCul+iqP1w6zkDW+/RaKYHvzVHzaXtMv3Wmv1t3+Em0jcHqTbO1+6BTbTJTjhv/gMQPqxuka8Eqp/sUXcLthnn7s/FCD7cZZutMGf9lOOLAetq7o8N6gHZIhZ4odfbO1fT9Bg18DXimVGJJSO9xKsYOWeij72DbxlO20PwD718GWP7Wv4w3Y/vo5k2zgD53sBv/Yft3U039LrpRS3RFIgxGz7dRRSx2UfXJs8B9f429t6mkN/pxJdhoyvl+c3NWAV0oNTIH0LoK/Hso/dsN/p53aRuN02/jFa0/ktgZ+duvjhD7VnTNmAS8iQWANEHD3s8IYc1es9qeUUj0ikAb5s+3UUajRtvGXf+I2+ey0zz9+pb1XD9ibqbcF/8T2xzhcwBXLGnwLcJ4xpl5E/MA7IvKKMea9GO5TKaViIykF8grs1FEkBJV73Fq/O5V/bIdriHQYQys1x63pT7SP2W7TT0Z+zIZsiFnAGzuKWb370u9OfWdkM6WU6gm+pM6v2nWiUL2/vcbf2uyz9Tl7RW8rf6odjfOmv/d40Me0DV5EvMAG4DTgAWPM+52sswRYAjBq1KhYFkcppXqPxwtDxtpp4lfb5xsDDWVu6LtNPuGmmNTie2W4YBEZBLwA/MAYs7Wr9TobLlgppVTXTjRcsKc3CmCMqQbeBC7ojf0ppZSKYcCLSI5bc0dEkoEvAztjtT+llFLH6lbAi8h4EQm4zxeJyK2t4X0CucBqEdkMfAD8wxjz11MrrlJKqe7q7knW54BCETkNeAR4GXgKuKirNxhjNgMzu1qulFIqtrrbROMYYyLA5cCvjTE/xNbQlVJK9VHdDfiwiFwD3AC0NrPoHZmVUqoP627AfweYB/zCGLNXRMYCT8auWEoppU5Vt9rgjTHbgVsBRGQwkG6M+WUsC6aUUurUdLcXzZsikiEiQ4CPgMdEZFlsi6aUUupUdLeJJtMYUwt8A3jMGDMb269dKaVUH9XdgPeJSC5wFe0nWZVSSvVh3Q34/wD+Duw2xnwgIuOAXbErllJKqVPV3ZOsfwb+3OH1HuCKWBVKKaXUqevuSdYRIvKCiJSKyFEReU5ERsS6cEoppU5ed5toHsMOT5AH5AN/cecppZTqo7ob8DnGmMeMMRF3ehzIiWG5lFJKnaLuBny5iFwrIl53uhaoiGXBlFJKnZruBvxN2C6SR4DDwJXY4QuUUkr1Ud0KeGPMfmPMpcaYHGPMUGPMZdiLnpRSSvVRp3JHp9t7rBRKKaV63KkEfM/fAlwppVSPOZWANz1WCqWUUj3uhFeyikgdnQe5AMkxKZFSSqkeccKAN8ak91ZBlFJK9axTaaJRSinVh2nAK6VUgtKAV0qpBKUBr5RSCUoDXimlEpQGvFJKJSgNeKWUSlAa8EoplaBiFvAiMlJEVovIDhHZJiK3xWpfSimlPqtbN90+SRHgfxtjPhSRdGCDiPzDGLM9hvtUSinlilkN3hhz2Bjzofu8DtiBvZ+rUkqpXtArbfAiMgaYCbzfybIlIlIkIkVlZWW9URyllBoQYh7wIpIGPAf8mzGm9vjlxpiHjDGFxpjCnBy9j7dSSvWUmAa8iPix4b7cGPN8LPellFLqWLHsRSPAI8AOY8yyWO1HKaVU52JZg18AXAecJyKb3OmiGO5PKaVUBzHrJmmMeQe9b6tSSsWNXsmqlFIJSgNeKaUSlAa8UkolKA14pZRKUBrwSimVoDTglVIqQWnAK6VUgtKAV0qpBKUBr5RSCUoDXimlEpQGvFJKJSgNeKWUSlAa8EoplaA04JVSKkFpwCulVILSgFdKqQSlAa+UUglKA14ppRKUBrxSSiUoDXillEpQGvBKKZWgNOCVUipBacArpVSC0oBXSqkEpQGvlFIJSgNeKaUSlAa8UkolKA14pZRKUDELeBF5VERKRWRrrPahlFKqa7GswT8OXBDD7SullDqBmAW8MWYNUBmr7SullDqxuLfBi8gSESkSkaKysrJ4F0cppRJG3APeGPOQMabQGFOYk5MT7+IopVTCiHvAK6WUig0NeKWUSlCx7Cb5NLAOmCQiJSJyc6z21bJrFyYSidXmlVKqX/LFasPGmGtite2OotXVFF97HYFx48i791ckjRzZG7tVSqk+r9830UhmBvtuPp+mTz5m72WXU/3iixhj4l0spZSKu34f8OUNNfzY/wb3/K8RBKZM4fBP7uTwT+7ECYXiXTSllIqrfh/wQSeFr+38EQ21mfxpyXlkf//71Lz0EvtvuolIVVW8i6eUUnHT7wM+NdXPGYNHcO7uf+KlrX9mz8WXkrd0Kc2bt1D8rW/RsmdPvIuolFJx0e8D3uv1cNGSM0hOCnD+7qv57l/uoW7BYkY9/jhObR17L/8GFY88or1slFIDTr8PeID0IUG++p1p5DSM5MyK4Vz2+6fYlTOWsS++QOrChZTet5S9V11F48aN8S6qUkr1moQIeICxM3KYumg4Zxw5l3yKuOr3r7LycIQRv/st+b/5DZGyMvZd80/svepqal5+WU/CKqUSXsIEPMA5V04mY6SfL+35BlMz39RMK7wAABQFSURBVOa2P63j7pe3wbmLGf/Kqwz72c9w6uo4dMeP2f3l86lcvlyDXimVsKQv9RkvLCw0RUVFp7SNlsYwTy19h7rDYd6f/A/WHl1AVkoaP71oMpfPzAdjaFi7jvIH/4emog34cnPJ+f73yfzG5YhIDx2JUkr1DhHZYIwp7HRZogU8QEtThD/e9yaNhw27Zqxlb3QuWw9EmDNmMD+/dBpT8zIwxtCwdi1l999P80ebSZ0/n9x7/l/8eXk9cCRKKdU7BlzAA4SaIvzh/7xBqMRHcf5G8ubP5Il3I9Q0hblu7mhuP38SmSl+jDFUP/ssR++9DxEh57ZbSf/qBfiHDe2RciilVCwNyIAHiEYc/vr0+5S820RlyiFGXBZgd8Vknlq/n9SAj2+fNZqbFoxhaEaQUMlBDv/sZzS+9x4AgYkTSTnzTJJGjcSfl4c/P5/A+PFIUlKPlU8ppU7VgA34Vls/LGbV4zuQsJeySTtZfOFXWFHUwKtbj+DzePh6QR7fWTCWKbnptOzcScO771L/zrs0bdqEaW5u244kJRGYMpmUggIyr7iC4MSJPV5WpZT6IgZ8wAPUVzfx9KOrCX0SpCa5jGHnw4LZX2L5uiOs2FBCUzjKWWOHcOP8MXxpyjCSfB6MMUSrqwkfOkSouJjmrdto2rKZ5i1bMS0tpC5cyJAbbiB1wXzEk1AdkpRS/YQGfAcbN+xi9VPbCTSkU5FRwrCFXi46+wJe2VLNH9bu42B1E1mpSXxjVj7fLBzJxGHpn9lGpKqK6mefpXL5cqJl5fhyckg//3zSz/8yvmHDkSQ/4k/Cl52FeL0xPR6l1MCmAX+caNjh739/j4/fqCCpMZXK1EOkzGrmsgvOZ39ZMs9+cIDXdxwl4him5mZw2cw8Lp2Rz/DM4DHbcUIh6v7xD+pe/Tv1a9ZgWlqOWS7JyQQmTiA4aTKpZy8k/dxztQ1fKdWjNOC7EI06vLlqI1tWHcRfk0ajv5bGCQc5a9FkCsacxcrNZby06SAfldQgArNGDeaC04dzwbThjByScsy2nIYGGj74AKe+ARMOY5qbbLPOzo9p3rEDp7YWb2YmGV/7GilzCvHn5uLLzcOXk63NO0qpk6YB/zmMMWz9aC9v/W0LHEgDDEcH7SX9DIdzFswiK2Uir2wp5dWtR9h+uBaAicPSWDx5KOdNGsqs0YPxe7sOaROJ0LB2LTUvvkTdqlXH1PS9Q4aQOncuqQvmEzzjDPx5eXjT0mJ9yEqpBKEB/wVUldWz6h9FlGyox9+QQlQilA7ZQ8ZkD3Pnnk7eoNN5c2clb+wsZf3eSiKOIS3gY+64ISw8LZv5p2UzYWhal1fFOo2NhA6UEDlymPChQzRt2kT92rVEy8rb1vGkpREYP57UBQtIXbiA5OnTEV/M7q6olOrHNOBPgnEMxbtKefftzZRvb8HfmIJDlNLMYvzjm5k8cyQzxs1kz6Ek3vm0nHc+LWdfRSMAWalJzB2XxazRgykYOYjT8zII+rs+2WqMoWXXLkK7dxM+dJjw4cM0b9lC05Yt4Djg9eLLzsY3bBiBsWPJuOhCUufPR/z+3vo4lFJ9lAb8KTLGcHBvBWvf3cLhrfX4alIBqA6WUpVzgMyxfiZMySdv8EQOlWby/t5q3ttTweEa24fe5xEm56ZTMHIQBSMHUzAyk7HZaXg9Jx77JlpTQ8O692jeuYPI0VIipaU0b91KtKbGNu0sXGBP2hqDJ5hMcsEMUubMwT98eMw/E6VU36AB38OqjjbwYdEnfLr5MKESP56orZ1XB0upyCjBnxshb/xghuXmE24ZSklZKltK6thcUkN9i73xSGqSl9PzM5mWl8nUvAxOz8tgfE4aSb4Tn3A1oRD177xDzct/oWnjRjAGRHDq63EaGgDw5eXiz82ztf6sIUgwGUny40lOIXn6GSTPmoUnEIjth6SU6hUa8DEUDTuU7q9l57b97P3kCA0lDp5m2xUyKhEqUw5TlXoEyW4hIzdASk4GUZNDVVUWnx7xs/NwHc1hB7A1/bHZqUwYlsZpQ9M5bWgap+WkMS4n9YRNPAAmGqXl449p/OADmjZvIVJWRqS8nGhFBU4oZE/sOnY/EgiQMnsWyTNnkTz9DILTpiFeL9GaGqK1tXiCQbzZ2XgHDWo7l2AiEfB6dcRNpfoYDfheZIyhrqKZkt0V7N59kKP7a2g+YpDm9vby+qQqKpOPUJ9Wjn+IIWlwgGhykEaTRlVdBofKkimp8OCY9jDNzQwyJiuVsTmpjM9JY7z7mJsZxHeCHjwdResbaNpQRMPatTSse4+WTz9tC/3OiN8Pfr/9cYhG8WZnkzpvHqnz5hE8fSreQYPxDh6ER/v2KxU3GvBxZoyhsTZEeUk9h4orOLC/lKrDjYQrPEi0PZzDnhZqAxXUBstpTKmBtChOiodQkpc6TxLVzckcrUyhrj4NE00DBJ9HyB+czMjBKeRmBskdlExuZpDhmUHyMpMZnhkkI+jrtObtNDTQvH07zdu3gwjezEw86RmY5ib7F0BZGSbqIIEkxO8ntLeYhnXriFZUHLMdX24u6YsXkXbel0iedjrRujqiVVVEysoI7T9A+MB+nIYGUubOI+3cc/ANGRLrj1ypAUMDvo9yHEN9VTM1pU2UHa7h0KFyKo/W0VAeJlrrPSb8AVq8jdQFqmhMqqExqZZIMEI4yaHJZ6hHqIoIpSEP4WgKJpqGiaRjIqmkJAUYnhkkNzPI0PQgQ9MD5KQHGJoRJCctQE56ElmpATKT/Xg+58SvcRzb42fvXqJVVUSrq2nauo2Gd989ZmC2jjwZGYjPR7SyEkQITJwIxuA0NWGiEYITJ5FcMIPkGTMITJ6Mb/DgE5fBGMIHD9Gy6xOSRo8mMG7cF/vglUogGvD9kDGGprowdRXN1FY0UVZaTenRKmoqG2iqiRCpA5p8CJ8N5BZvE82+epr8dgr7Wwh5I7R4ozRKlHrj0IjQjJcmfDQbPyEngJggGUmZDErOICs5gyGpAQanJJGZ4mdQchKZyX4ykn1kBP1kJPvJdKeMoA9PqIWGdesIFe/DO2gQ3sGD8GVnkzRyJN5BgzDG0Lx9O/Wr36Rp80dIUhKe5BRw54f27Gkrvzc72w7N7PNhQiF7ZbDj2BPK0SihAwdw6ura1k+eOZNBV15Bypw5eNLS8KSmEjl6lKaNG2ncuBGnthbfsOH4hw/DNzwXf34+/vy8Y84xKNVfacAnqGjUobkuTENNC421Iaqr6qmsrKG6uoGG2maa68OEGhycJoEWb1tvn063JVFC3iZC3mZCvibCnhZC3hAhb5iQRGmRCCGPQ1gMIYEwEEII4yGMB7w+fElJ+P0BkgJBUgIppAVSyAykkRlMZVAwhfRgEilJPlIDXlKTfKS0PiZ5CTY34N21A0/xXqKf7iJcXAzGIH4/kuQHjxdEQMCfl0dw8mQCp51G00ebqV6xgtDevZ0elyctDe+QIUSOHv3sWEGBAN6MDDyZGXhSUxGfH/F6EZ+XvPvuw5eV1YPfllKxcaKAj+nlkSJyAfAbwAv83hjzy1jub6Dxej2kDgqQOqi1y2P2CdcPt0RpbgjT0himuT5MXV0j1bV11NbV09DQQlODh5amJMJNqURaDNFmMM2ChL1I2IvHdH9kTINDxBMm7K0k4jlMvSdMtSdMxBMlIhGi4hCRKBFxiIohKoYI9nnEn40zMQvj9YAAXkE8XsTrweP14PF68ZXX463ait+XhO+q68gtq2BwbS3JkTDBUAgnPZXG0yYQGTWK5OQgQa+P5JYQKZUVpFRWEiwvx19VgdNQj6ehHmlqRKJRJBxBWkLUtYQJhqL4vPY8h9b0VX8Usxq8iHiBT4DzgRLgA+AaY8z2rt6jNfi+LRpxCLdECTVHiLQ4hFrCNDQ2Ud/YSGNTM41NzTQ1t9DSEibUEibUHCEcihIJRYm0OETCBidicMJARCAqSNSLOILHsX9heE1s6hwODkYcHIm6k9P2aMTBwcER484zGIw739jXYnCwj20TBiNgOzvZ57S+7vCImLa/PkSkw3NApO0Rj10u7jwRQdwfl7ZHETwe9zXtrz0eD3gED4JHBI/XXSaeDuvY1x6vIHjc1/a9Ho8g4sHrrtf2XDyIB7weLx4RvB6P3YYH9312+z6vx+77uG16xdO2Xtv73XKKV+w+sD/cXnHnu8fjdbcjIvg8HrxeD4LdhvsR2s/E/fgG6o9wvGrwZwKfGmP2uIV4Bvg60GXAq77N6/Pg9XkIpnYcImFQj+7DGEM04hANO0Qj9nkoFKYlHCIUCtMcaiEcjhAKh2gJhQlHInYKR4hE7A9KcyhCOBIl0jY5mKjBidptOo6DEzU4UYNxDMaxJ7xxwOMI4ggYwHjBEcQARhAjba/FTXaP8SDuMnETXVrnI0jrcve5h74zcqjjTpYBonEryxdlf27ts9Yf2PZl7hIxbXO6ni8nWN8l5pitd76tjmUztJ8a6/jezpbb1yFfiP9Yem3XB3ySYhnw+cCBDq9LgLOOX0lElgBLAEaNGhXD4qj+QETw+b34jrmwK9jl+v2NMQZj7COOfXSiDmEninEcItEoUcfBcaJEolEcx+AYOz8SdewPVzSC4xgijkM4GrU/XO57HccQNQ7RiINjjn3uGEM0GsUYcByHqGMAQ9T9UQVj9+c4bWV0HAfH0LbMlt89Bsf9K8ZwzHxMx/n2vcY91tbPAOMGnWn/XOyjnS/GDd7WdY3QFpat/2l7b8cPuO0/xy5rmy/HrGPcrG1dT45/3zEbak9lMR330v76uN+a48rV9Xzjj01LSiwDvrO/lz5zFMaYh4CHwDbRxLA8SsVda/MLiD0zBYCXJHTgONXzYvn3YgkwssPrEcChGO5PKaVUB7EM+A+ACSIyVkSSgG8BL8dwf0oppTqIWRONMSYiIt8H/o79Y/RRY8y2WO1PKaXUsWLaD94YsxJYGct9KKWU6lzf6bOllFKqR2nAK6VUgtKAV0qpBKUBr5RSCapPjSYpImXAvpN8ezZQ3oPF6Q8G4jHDwDzugXjMMDCP+4se82hjTE5nC/pUwJ8KESnqasCdRDUQjxkG5nEPxGOGgXncPXnM2kSjlFIJSgNeKaUSVCIF/EPxLkAcDMRjhoF53APxmGFgHnePHXPCtMErpZQ6ViLV4JVSSnWgAa+UUgmq3we8iFwgIh+LyKci8pN4lydWRGSkiKwWkR0isk1EbnPnDxGRf4jILvdxcLzL2tNExCsiG0Xkr+7rsSLyvnvMz7rDUScUERkkIitEZKf7nc9L9O9aRH7o/tveKiJPi0gwEb9rEXlUREpFZGuHeZ1+t2Ld7+bbZhGZ9UX21a8D3r2x9wPAhcBU4BoRmRrfUsVMBPjfxpgpwFzgX91j/QmwyhgzAVjlvk40twE7Orz+FfBf7jFXATfHpVSx9RvgVWPMZGAG9vgT9rsWkXzgVqDQGDMNO8T4t0jM7/px4ILj5nX13V4ITHCnJcD/fJEd9euAp8ONvY0xIaD1xt4Jxxhz2Bjzofu8Dvs/fD72eP/grvYH4LL4lDA2RGQE8DXg9+5rAc4DVrirJOIxZwDnAI8AGGNCxphqEvy7xg5fniwiPiAFOEwCftfGmDVA5XGzu/puvw48Yaz3gEEiktvdffX3gO/sxt75cSpLrxGRMcBM4H1gmDHmMNgfAWBo/EoWE78G7gAc93UWUG2MibivE/E7HweUAY+5TVO/F5FUEvi7NsYcBJYC+7HBXgNsIPG/61ZdfbenlHH9PeC7dWPvRCIiacBzwL8ZY2rjXZ5YEpGLgVJjzIaOsztZNdG+cx8wC/gfY8xMoIEEao7pjNvm/HVgLJAHpGKbJ46XaN/15zmlf+/9PeAH1I29RcSPDfflxpjn3dlHW/9kcx9L41W+GFgAXCoixdjmt/OwNfpB7p/xkJjfeQlQYox53329Ahv4ifxdfxnYa4wpM8aEgeeB+ST+d92qq+/2lDKuvwf8gLmxt9v2/AiwwxizrMOil4Eb3Oc3AC/1dtlixRhzpzFmhDFmDPa7fcMY821gNXClu1pCHTOAMeYIcEBEJrmzvgRsJ4G/a2zTzFwRSXH/rbcec0J/1x109d2+DFzv9qaZC9S0NuV0izGmX0/ARcAnwG7g/4p3eWJ4nAuxf5ptBja500XYNulVwC73cUi8yxqj418E/NV9Pg5YD3wK/BkIxLt8MTjeAqDI/b5fBAYn+ncN/BzYCWwF/ggEEvG7Bp7GnmcIY2voN3f13WKbaB5w820LtpdRt/elQxUopVSC6u9NNEoppbqgAa+UUglKA14ppRKUBrxSSiUoDXillEpQGvBqQBGRqIhs6jD12BWiIjKm4wiBSsWb7/NXUSqhNBljCuJdCKV6g9bglQJEpFhEfiUi693pNHf+aBFZ5Y7FvUpERrnzh4nICyLykTvNdzflFZGH3XHNXxOR5LgdlBrwNODVQJN8XBPN1R2W1RpjzgR+hx3zBvf5E8aY6cBy4H53/v3AW8aYGdhxYra58ycADxhjTgeqgStifDxKdUmvZFUDiojUG2PSOplfDJxnjNnjDup2xBiTJSLlQK4xJuzOP2yMyRaRMmCEMaalwzbGAP8w9qYNiMiPAb8x5p7YH5lSn6U1eKXamS6ed7VOZ1o6PI+i57lUHGnAK9Xu6g6P69zna7EjWQJ8G3jHfb4K+C603TM2o7cKqVR3ae1CDTTJIrKpw+tXjTGtXSUDIvI+tuJzjTvvVuBREfl37F2WvuPOvw14SERuxtbUv4sdIVCpPkPb4JWirQ2+0BhTHu+yKNVTtIlGKaUSlNbglVIqQWkNXimlEpQGvFJKJSgNeKWUSlAa8EoplaA04JVSKkH9/xnVLgWj5ynwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(relu_res_history.history['accuracy'])\n",
    "plt.plot(L2_res_history.history['accuracy'])\n",
    "plt.plot(lr_res_history.history['accuracy'])\n",
    "plt.plot(drop_res_history.history['accuracy'])\n",
    "plt.plot(tanh_res_history.history['accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['ReLU','L2', 'Leaky ReLU','drop out','tanh'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(relu_res_history.history['loss'])\n",
    "plt.plot(L2_res_history.history['loss'])\n",
    "plt.plot(lr_res_history.history['loss'])\n",
    "plt.plot(drop_res_history.history['loss'])\n",
    "plt.plot(tanh_res_history.history['loss'])\n",
    "plt.title('Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['ReLU','L2', 'Leaky ReLU','drop out','tanh'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return false positive, fasle negative, prediction lable(0,1) for test set   \n",
    "def pred_and_error(model,X_test,Y_test,df_test):\n",
    "    err_fp=[]\n",
    "    err_fn=[]\n",
    "    Y_test_pred=[]\n",
    "    for i in range(len(X_test)):\n",
    "        pred_result_gold= np.argmax(model.predict(X_test[i].reshape(1,-1)))\n",
    "        Y_test_pred.append(pred_result_gold)\n",
    "        if Y_test[i] != pred_result_gold:\n",
    "            if Y_test[i] == 0:\n",
    "                err_fn.append((df_test[i],i))\n",
    "            else:\n",
    "                err_fp.append((df_test[i],i))\n",
    "    return err_fp,err_fn,Y_test_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return top num errors of false positive and false negative individually  \n",
    "def most_num_error(model_list,X_test,Y_test,df_test,num):\n",
    "    fre_index_fp={}\n",
    "    fre_index_fn={}\n",
    "    fre_error_fp=[]\n",
    "    fre_error_fn=[]\n",
    "    for model in (model_list):\n",
    "        err_fp,err_fn,Y_test_pred=pred_and_error(model,X_test,Y_test,df_test)\n",
    "        for error in err_fp:\n",
    "            if error[1] in fre_index_fp:\n",
    "                fre_index_fp[error[1]]+=1\n",
    "            else:\n",
    "                fre_index_fp[error[1]]=1\n",
    "        for error in err_fn:\n",
    "            if error[1] in fre_index_fn:\n",
    "                fre_index_fn[error[1]]+=1\n",
    "            else:\n",
    "                fre_index_fn[error[1]]=1\n",
    "    sorted_fp=sorted(fre_index_fp.items(),key=operator.itemgetter(1),reverse=True)[:num]\n",
    "    for i in range(len(sorted_fp)):\n",
    "        fre_error_fp.append((df_doc_test[sorted_fp[i][0]],sorted_fp[i][1]))\n",
    "    sorted_fn=sorted(fre_index_fn.items(),key=operator.itemgetter(1),reverse=True)[:num]\n",
    "    for i in range(len(sorted_fp)):\n",
    "        fre_error_fn.append((df_doc_test[sorted_fn[i][0]],sorted_fn[i][1]))\n",
    "    \n",
    "    return fre_error_fp,fre_error_fn\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess single review  \n",
    "def standarize_test(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return  X_test\n",
    "\n",
    "def preprocess_test(df_train,df_error):\n",
    "    \n",
    "    vocabulary=get_vocabulary(df_train)\n",
    "    \n",
    "    X_train, Y_train = text2vec(df_train,vocabulary)\n",
    "    \n",
    "    X_error, Y_error = text2vec(df_error,vocabulary)\n",
    "    \n",
    "    X_error=standarize_test(X_train, X_error)\n",
    "    \n",
    "        \n",
    "    return X_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "def confusion_mx(Y_test_pred,Y_test):\n",
    "    conf_mx=confusion_matrix(Y_test_pred,Y_test)\n",
    "    sns.heatmap(conf_mx, annot=True)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    row_sums=conf_mx.sum(axis=1,keepdims=True) \n",
    "    norm_conf_mx=conf_mx/row_sums\n",
    "    sns.heatmap( norm_conf_mx,annot=True)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.title('confusion matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabulary_test(df_true_false,num):\n",
    "    dict_word_freq={}  \n",
    "    for i in range(0,len(df_true_false)):\n",
    "      sentence_tokens=get_list_tokens(df_true_false[i])\n",
    "      for word in sentence_tokens:\n",
    "        if word in stopwords: \n",
    "          continue\n",
    "        if word not in dict_word_freq: \n",
    "          dict_word_freq[word]=1\n",
    "        else: \n",
    "          dict_word_freq[word]+=1\n",
    "\n",
    "    sorted_list = sorted(dict_word_freq.items(), key=operator.itemgetter(1), reverse=True)[:num]\n",
    "    vocabulary=[]\n",
    "    for word,frequency in sorted_list:\n",
    "      vocabulary.append(word)\n",
    "    \n",
    "    return vocabulary \n",
    "\n",
    "#return most frequently used words in true reviews and deceptive reviews\n",
    "def unique_voca(ds_true,ds_false,num):\n",
    "    unique_true_doc=[]\n",
    "    unique_false_doc=[]\n",
    "    voca_true_doc=vocabulary_test(ds_true,num)\n",
    "    voca_false_doc=vocabulary_test(ds_false,num)\n",
    "    for i in voca_true_doc:\n",
    "        if i not in voca_false_doc:\n",
    "            unique_true_doc.append(i)\n",
    "    for i in voca_false_doc:\n",
    "        if i not in voca_true_doc:\n",
    "            unique_false_doc.append(i)\n",
    "    return unique_true_doc,unique_false_doc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most 4-true but predict as false(0):\n",
      "\n",
      "([\"'This is a fantastic doctor!!!  I went to him b/c I had already had two capsular contractures since my previous breast augmentation.  He was very helpful, patient, and answered all of my questions.  I quickly scheduled my surgery, and I am beyond happy with the results.  I will definitely be using him again the future!!\", 1], 5)\n",
      "\n",
      "(['\"I know you probably don\\'t need to read another review about how amazing Doctor Forrest is but one feels the pressing need to tell the world about this surgeon. He is extraordinary. He is kind, patient, gentle and brilliant at what he does. If you get referred to Doctor Forrest count yourself a hundred thousand times lucky. He operated on my daughter for her craniosynistosis and did such a wonderful job. He goes above and beyond the call of duty and makes you feel you are taken care of and listened to. I think he is the finest doctor I have ever encountered. His staff obviously feel the same as every nurse and practitioner I encountered at Toronto Sick Kids spoke of him with the most revered tone and respect. Simply Amazing.', 1], 4)\n",
      "\n",
      "([\"'After leaving my previous doctor in tears because she said I had to see a psychiatrist as there was nothing wrong with me I vowed to find a more understanding doctor. I am very fortunate that Dr. Nave was taking new patients when I began my search. I have fibromyalgia and chronic pain and all the problems that go with it. Dr. Nave does not try to cram too many patients into a day so she has the time to spend and to a listening ear as well as sound medical advice. On a rare occasion when she is running a few minutes late she apologizes for keeping me waiting. We need more doctors like her who are caring for patients first and making money second.\", 1], 2)\n",
      "\n",
      "([\"'I would recommend Dr. Hasell.  I had a BA on July 22 and I am very happy with the results.  Peggy was friendly with me in person and on the phone.  I called a couple of times with questions after my surgery and she was very helpful.  Dr. Hasell called me back at home the day after surgery because I had concerns about having lots of swelling in my body.  He said it was due to the anesthetic and the I.V. Also, just prior to surgery I was quite emotional and he was very comforting with me.\", 1], 1)\n",
      "\n",
      "most 4-Fasle but predict as true(1) :\n",
      "\n",
      "([\"'This doctor did a miracle with my breats lift and augmentation. It has been three months now and it is perfection.  All the other doctors that I saw told me that I would have to get other surgeries after the first one because I was a difficult case and they were charging me $13,000 plus the touch up.  Dr. Silverman is so calm and perfectionnist and his staff is super.  I am getting another surgery with him and I trust him like I never trust any doctors before.\", 1], 5)\n",
      "\n",
      "(['\"Dr.Stalker is a very friendly and knowledgeable doctor! She has a lot of patience and is highly willing to explain everything about your options, medications and procedures to you, and makes great recommendations. She\\'s efficient and doesn\\'t make you wait too long, but gives enough time to each of her patients to make sure you feel comfortable. Plus, she\\'s very reliable with regard to the quality of care you\\'ll get. Excellent doctor!', 0], 5)\n",
      "\n",
      "([\"'Dr. Luna is a great doctor. Not only does he help with my ailment and treat me, but he goes above and beyond to connect with me and make me comfortable. He always takes time to ask me about my life and asks about my grandchildren. The wait time is consistently less than 10 minutes. His support staff is very nice and professional. Even though he is a very popular doctor, he still works me in when I really need to be seen.\", 0], 5)\n",
      "\n",
      "(['\"To this day, I cannot thank Dr. Elhai enough for what he has given back to me. I had a severe cleft lip, which my family could not afford to fix through surgery. Thus, I would always find myself being picked on by other people during school. One time, the bullies were particularly mean and they decided that my face was apparently not ugly enough because they proceeded to pummel my face to a bloody pulp. Following weeks of emergency room recovery, my nose was contorted out of position due to it being fractured and both of my cheeks were misshaped due to their multiple fractures. The doctors in Whales said that there was nothing that they could possibly do due to the degree of damage done to my face. Needless to say, I was mortified; I didn\\'t want my face to attract any more negative attention. ', 0], 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fre_error_fp,fre_error_fn=most_num_error([relu_res,L2_res,lr_res,tanh_res,drop_res],X_res_test,Y_res_test,df_res_test,4)\n",
    "print(\"most 4-true but predict as false(0):\\n\")\n",
    "for i in range(len(fre_error_fp)):\n",
    "    print(fre_error_fp[i],end=\"\\n\\n\")\n",
    "print(\"most 4-Fasle but predict as true(1) :\\n\")\n",
    "for i in range(len(fre_error_fn)):\n",
    "    print(fre_error_fn[i],end=\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error1=[[\"'This is a fantastic doctor!!!  I went to him b/c I had already had two capsular contractures since my previous breast augmentation.  He was very helpful, patient, and answered all of my questions.  \\\n",
    "I quickly scheduled my surgery, and I am beyond happy with the results.  \\\n",
    "I will definitely be using him again the future!!\", 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_error1=preprocess_test(df_doc_train,df_error1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu_res [[0.56588644 0.43411356]]\n",
      "L2_res [[0.4893885 0.5106115]]\n",
      "lr_res [[0.47576532 0.5242347 ]]\n",
      "tanh_res [[0.47283974 0.5271602 ]]\n",
      "drop_res [[0.5822308  0.41776922]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "model_list=[(relu_res,\"relu_res\"),(L2_res,\"L2_res\"),(lr_res,\"lr_res\"),(tanh_res,\"tanh_res\"),(drop_res,\"drop_res\")]\n",
    "for i in model_list:\n",
    "    print(i[1],i[0].predict(X_error2.reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_fp,err_fn,Y_test_pred=pred_and_error(tanh_res,X_res_test,Y_res_test,df_res_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_true_res,unique_false_res=unique_voca(ds_res_true,ds_res_false,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['love', 'decided', 'favorite', 'weber', 'perfectly', 'family',\n",
       "       'quality', 'signature', 'anyone', 'quartino', 'taste', 'looking',\n",
       "       'sure', 'pig', 'highly', 'ditka', 'prime', 'never', 'absolutely',\n",
       "       'new', 'feel', 'purple', 'arrived', 'full', 'something',\n",
       "       'perfection', 'way', 'overall', 'selection', 'greeted', 'found',\n",
       "       'last', 'clean', 'quickly', 'girl', 'loved', 'mike', 'fantastic',\n",
       "       'tried', 'flavor', 'entree', 'started', 'find', 'decor', 'soon',\n",
       "       'course', 'ca'], dtype='<U10')"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(unique_false_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['people', 'view', 'plate', 'side', 'two', 'day', 'served',\n",
       "       'without', 'cake', 'tasty', 'took', 'small', 'around', 'ate',\n",
       "       'large', 'hour', '2', 'burger', 'though', 'fun', 'pork',\n",
       "       'different', 'lot', 'big', 'shared', 'see', 'potato', 'sauce',\n",
       "       'share', 'top', 'pizza', 'item', 'year', 'know', 'enough',\n",
       "       'attentive', 'rib', 'going', 'lobster', 'outstanding', 'busy',\n",
       "       'enjoy', 'three', 'long', 'cheese', 'chicken', \"'d\"], dtype='<U11')"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(unique_true_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_fp,err_fn,Y_test_pred=pred_and_error(tanh_res,X_res_test,Y_res_test,df_res_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_mx(Y_test_pred,Y_res_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Group 14_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
